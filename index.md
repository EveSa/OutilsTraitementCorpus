# üë© Qui suis-je üë© 

- Eve Sauvage
- ancienne √©tudiante du master TAL
- doctorante au LISN √† l'universit√© Paris-Saclay
- mon sujet : `le traitement des s√©quences longues avec les mod√®les d'apprentissage profond`

**Me joindre :** 

- üì´  eve.sauvage at lisn dot fr *avec "outils de traitement de corpus" dans l'objet svp*
- üåê  <https://EveSa.github.io/OutilsTraitementCorpus>

#  üéì Pr√©senter le cours üéì

**Comment √ßa va ce passer :** 

- 6 s√©ances 
- du 18 mars au 13 mai
- de 15h30 √† 18h30
- En salle 308
- partag√© en 3 parties : 
  - Une partie cours magistral
    \&rarr; n'h√©sitez pas √† poser des questions
  - Une partie retours 
    - sur le cours
    - pr√©paration du cours d'apr√®s (qu'est ce que vous voulez voir la prochaine fois, de quoi vous voudriez entendre parler)
    - un petit point bonnes pratiques
  - Une partie pratique

**√âvaluation :** 

On fait un projet de constitution/exploitation de corpus en faisant

Un TP apr√®s chaque s√©ance, sauf la premi√®re et la derni√®re, sur Github.
7 s√©ances, 5 TP, 1 projet

Tous vos devoirs devront m‚Äô√™tre parvenus avant le 26 mai

# Index des cours

- [Cours 1](/slides/cours1-2024.html)
- Cours 2
  - [slides](/slides/cours2-2025.html)
  - [notebook](/notebooks/web_scrap.ipynb)
- Cours 3
  - [slides](/slides/cours3-2025.html)
  - [notebook](/notebooks/web_scrap.ipynb)
- Cours 4
  - [slides](/slides/cours4-2025.html)
  - [notebook](/notebooks/visualise_data.ipynb)
  - [Dockerfile](/src/dockerssh.zip)
- Cours 5
  - [slides](/slides/cours5.html)
  - [notebook](/notebooks/significativity_test.ipynb)
- Cours 6
  - [slides](/slides/cours6.html)

Acc√®s √† la newsletter &rarr; [newsletter](./newsletter.md)

## D√©roul√© des TP

#### TP 1 :

Partie 1 | √©tude de cas *CoNLL 2003* :

1. Quelle type de t√¢che propose CoNLL 2003 ?
2. Quel type de donn√©es y a-t-il dans CoNLL 2003 ?
3. A quel besoin r√©pond CoNLL 2003 ?
4. Quels types de mod√®les ont √©t√© entra√Æn√©s sur CoNLL 2003 ?
5. Est un corpus monolingue ou multilingue ?

Partie 2 | projet:

En vous inspirant des informations que vous avez r√©cup√©r√©es pour CoNLL 2003, d√©finissez les besoins de votre projet:
- dans quel besoin vous inscrivez vous ?
- quel sujet allez vous traiter ?
- quel type de t√¢che allez vous r√©aliser ?
- quel type de donn√©es allez vous exploiter ?
- o√π allez vous r√©cup√©rer vos donn√©es ?
- sont-elles libres d'acc√®s ?

#### TP 2:

R√©cuperer votre corpus de travail √† partir d'une resource web (pas d'API)

mettez votre script de crawling et de scraping sur votre github en respectant l'arborescence de dossiers pr√©sent√© au cours 3

#### TP 3:

Visualiser votre corpus et r√©aliser des statistiques de texte
 
    ex. :
    1. longueur des textes
    2. mots fr√©quents (zipf)
    3. les statistiques adapt√©es √† votre t√¢che

#### TP 4 : 

- A partir des donn√©es que vous avez r√©cup√©r√©es, caugmentez vos donn√©es en cr√©ant un dataset synth√©tique.
- Choississez l'architecture adapt√©e √† votre t√¢che et trouvez un mod√®le qui correspond √† votre t√¢che et √† cette architecture.

#### TP 5

- Finetuner le mod√®le pretrained qui correspond le plus √† vos donn√©es gr√¢ce au trainer d'hugging face

#### TP 6

- Evaluer votre mod√®le
