---
layout: presentation
title: Cours1
---

# Outils de Traitement de Corpus

Eve Sauvage - doctorante à EDF R&D

📫eve.sauvage at lisn dot fr📪

Essayez de mettre "Outils de Traitement de Corpus" dans l'objet.

🌐[EveSa.github.io/OutilsTraitementCorpus](EveSa.github.io/OutilsTraitementCorpus)🌐

📜 Traitement des séquences longues avec les modèles d'apprentissage profond

<aside class="notes">
    Vous m'appelez Eve et on se tutoie si vous n'avez pas d'objection -> Je connais certains d'entre vous et je viens de
    terminer ce master.
    Je ne suis pas une figure hierarchique.
</aside>

-vertical-

## Organisation du Cours

📅6 x 3 heures📅

⏱️ découpés en sessions de 10 à 30 min: ⏱️

- un point sur l'actualité
- Correction des quizz précédents
- 1ère partie du cours
- un petit test
- 2e partie du cours
- un point sur les bonnes pratique
- un petit test
- un TP

<aside class="notes">
    Profitez de la partie retour pour me dire les notions que vous souhaiterez voir aborder
    Les points, même des autres cours que vous n'avez peut être pas compris
    etc...
</aside>

-vertical-

<p>les slides sont disponibles en ligne</p>

<aside class="notes">
    L'objectif c'est que vous ne soyez pas obligés de venir en cours pour Suivre
    Ne prenez pas de photo des slides, ne copiez pas frénétiquement ce qu'il y a écrit
    Ne venez pas faire du bruit inutilement, ça ne me dérange pas que vous ne soyez pas là
    ça ne veut pas dire "ne venez pas". Je suis là pour
    - éclaircir les points qui ne vous paraissent pas clair
    - répondre à vos questions
</aside>

-vertical-

## Les objectifs

- définir les données dont on a besoin
- récupérer des données depuis le web
- adapter des données au besoin
- adapter des données pour le traitement machines
- entraîner un modèle avec une architecture pré-définie
- évaluer les modèles

-vertical-

## Les objectifs

- savoir se tenir au courant
- savoir tenir un code propre
- savoir utiliser un gestionnaire de version
- savoir tester son code
-

-vertical-

## Evaluation

3 notes au total :

2 rendus obligatoires :

- un projet de constitution et de traitement de corpus (40%)
- un post sur la newsletter (20%)

1 rendu obligatoire entre :

- les quizz en sessions
- un devoir sur table à la dernière séance

&rarr; Je choisirais la meilleure des deux notes (40%)

-vertical-

## Evaluation

<p class="r-fit-text">📚📄Evaluation de corpus au cours d'un projet en 6 séances📄📚</p>

l'objectif :

- constituer un corpus à partir de données du web
- évaluer la qualité du corpus avec les différents outils vus en cours
- stocker les données dans un format accessible
- choisir un modèle à évaluer sur le corpus
- bonus : finetuner le modèle choisi

A rendre sur Git

-vertical-

## Evaluation

<p class="r-fit-text">📚📄Evaluation de corpus au cours d'un projet en 6 séances📄📚</p>

Les critères :
- respect des points "bonnes pratiques"
- compréhensibilité du projet
- production graphique

<aside class="notes">
    -> pourquoi je vous fais rendre sur Github ❓

    - les (bons) recruteurs regardent votre github avant votre CV
    - les (bons) chercheurs regardent le github avant les papiers
    - Si vous faites des erreurs, vous êtes pas perdus

    -> Les critères d'évaluation:
    - surtout le respect des bonnes pratiques
    - et ensuite si vous avez effectué le travail demandé
</aside>

-vertical-

## Evaluation

📮Participer à la newsletter📮

Pour apprendre à se tenir informé dans le monde de la tech:

Réaliser au moins un post sur la [newsletter](../newsletter.html) au cours des 7 semaines de cours.

et le présenter en cours en faisant une rapide explication et en répondant aux questions de l'assemblée.

-vertical-

## Evaluation - Newsletter

critères d'evaluation :
- récence et intérêt de l'information
- exclusivité de l'information
- compréhensibilité du contenu

-vertical-

## Evaluation

2 petits quizz à chaque séances sur le contenu de la session

- du code
- des bonnes pratiques
- de la théorie
- ...

&rarr; chaque séance sera noté sur 5

-horizontal-

Petite revue des [nouvelles](../newsletter.html)

-horizontal-
# Cours 1 - Définir le problème :interrobang:

<h2 class="r-fit-text">📚📄Rappels sur les corpus et l'apprentissage📚📄</h2>

## 🛠️Focus sur les tâches🛠️

<!-- à décaler cours 2
## 🔎Où trouver des corpus🔍
-->

-vertical-

## Outils de Traitement de Corpus

### 📄📚Qu'est ce qu'un corpus📚📄
<!--normalement vous savez ce que c'est-->

- Une collection de documents
- Sur un thème particulier
- Pour une tâche particulière

---
Avant de revenir sur ces caractéristiques :

<aside class="notes">
    les documents peuvent être de nature différentes :
    - texte
    - image
    - son
</aside>

-vertical-
<h3 class="r-fit-text">❓A quoi ça sert les données❓</h3>

**Pour la linguistique**

Pour vérifier des hypothèses ou inférer des comportements linguistiques

**Pour la littérature**

Realiser des statistiques textuelles

-vertical-
<h3 class="r-fit-text">❓A quoi ça sert les données❓</h3>

**Pour l'apprentissage**

à partir des observations (*données*), on peut déterminer des paramètres (*features*) qui vont nous permettre de prédire
le futur

<img src=https://www.baeldung.com/wp-content/uploads/sites/4/2022/03/1_latent-1024x307.png alt="latent space">

-vertical-

**un exemple (simpliste)*

⛅Comment savoir comment s'habiller demain ?⛅:
- la saison ❄🌺
- la couverture nuageuse de la journée précédente ☁
- le vent 🍃
- la météo des régions voisines 🌍
- ...

Comment on en est arrivé à ces conclusions ? ➡️ les observations
<p class="fragment r-fit-text">Un exemple plus linguistique &rarr; l'acquisition du language chez les enfants</p>

<aside class="notes">
    C'est une représentation simpliste pour vous aider à comprendre comment ça fonctionne
    On ne prédit pas la météo avec des paramètres aussi simples
    Est-ce que vous voyez une meilleur exemple de chose à prévoir qui soit en lien avec le NLP?
</aside>

-vertical-

<h3 class="r-fit-text">🤖Pour les machines, c'est pareil🤖</h3>

On a besoin de **données** pour apprendre les **paramètres** qui permettent de prédire le futur

&rarr; On collecte des corpus (*datasets*)

C'est comme ça qu'on obtient des modèles **prédictifs**

-vertical-

## On peut maintenant revenir sur les caractéristiques de notre corpus📚📄

-vertical-

### Une collection = un nombre représentatif de données

**Pour couvrir suffisamment de cas**

---

⛅Prévoir la météo⛅

- nuage ☁ = pluie 🌧
- vent 🍃 = beau temps &#9728;&#65039;
- nuage ☁ + vent 🍃 = ❓

-vertical-

### Un thème

**Pour éviter le bruit**

---

⛅Prévoir la météo⛅

- mon humeur de ce matin 🎭
- le nombre de café que j'ai bu ☕
- les traces de bouctins devant chez moi 👣
- ...

-vertical-

### Pour une tâche donnée

**Pour avoir la sortie voulue**

---

| | |
|:---:|:---:|
| ❄🌺 | ❄🌺 |
| ☁ | ☁ |
| ... | ... |
|&rarr; |&rarr; |
|⛅Prédire la météo⛅|🦜Parler de la pluie et du beau temps🦜|

-vertical-

### ❓ A quel point c'est important ❓
<!-- Pourquoi on vous parle de corpus tout le temps ?
    Corpus Parallèle et Comparable / Outils de traitement de corpus / Enrichissement de corpus / ...
-->
C'est le nerf de la guerre

Les entreprises publient :

✔️ 🏠 les architectures

✔️ 🔩 les poids des modèles

❌ 📚 mais pas les données

-vertical-

### Obtenir des données

&rarr; Avec internet, c'est plus si compliqué

### Obtenir des données *utiles*

&rarr; C'est très couteux 💸💸💸

-vertical-

### Les problématiques des données

- La propreté des données ✨
- quand on récupère les données sur internet, on a de tout

- L'annotation des données🏷️
- Pour réaliser certaines annotations, on a besoin d'experts et ça coûte cher

-vertical-

### Les problématiques des données

- Le RGPD 🕵️‍♂️
- particulièrement visible dans le domaine médical &rarr; alors que les modèles sont très bons pour prédire les
pathologies

- La représentativité des données
- Les données peuvent être biaisées &rarr; avoir des caractéristiques qu'on voudrait éviter

-horizontal-

<h2 class="r-fit-text">🛠️Les tâches et les corpus🛠️</h2>

En *Machine Learning*, on fait de la prédiction :

- pour catégoriser les éléments existants (classification)
- pour découvrir de nouveaux éléments (regression)

❓ Qu'en est-il de prédire la météo de demain ❓

<aside class="notes">
    Quand vous décidez comment vous habillez le matin/pour prévoir la météo, vous faites quel type de prédiction ?
    Levez la main haut pour réponse 1 et la main pas trop haut pour réponse 2
    (la bonne réponse c'est réponse 2)
</aside>

-vertical-

<img src="https://miro.medium.com/v2/resize:fit:1400/1*xs6Jr4iAPvoqszF9JgDWOA.png">

-vertical-

<h3 class="r-fit-text">🏷️Catégorisation d'éléments existants en NLP🏷️</h3>

- POS tagging
- Analyse de sentiment
- NER
- Transcription
- ...

-vertical-

<h3 class="r-fit-text">🌱Génération de nouveaux éléments en TAL🌱</h3>

❓

<p class="fragment">On a pas beaucoup de tâche de régression en TAL</p>

-vertical-

<h3>Et la génération de texte ❓</h3>

⚠️En TAL, la génération de nouveaux éléments, ce n'est souvent pas de la régression

- Chatbot
- QuestionAnswering
- Traduction
- Résumé Automatique
- ...

&rarr; Tout ça, ce sont des tâches de *Next-Token Prediction*

-vertical-

<h3>Comment se passe la NTP</h3>

<img src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/06/general-workflow-for-prompt.png">

-vertical-

### Avant de sélectionner son corpus

<div class="r-stack">

    &rarr; bien déterminer la tâche que l'on veut traiter :

    - son besoin en ressources
    - quel modèle on utilise ? *Machine Learning*/*Deep Leaning* ?
    - les langues que l'on va traiter
    - monolingue/multilingue
    - traduction ? (corpus Parallèle)
    - le genre des textes
    - ex : résumé d'article de journaux vs. résumé de décision de justice

    <img class="fragment fade-in-then-out"
        src="https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png">
</div>

-vertical-


### Critères de définition d'un corpus

- Taille (en nb de mots le plus souvent)
- Annotations (niveaux et outils utilisés)
- Statut de la documentation (guidelines, publication scientifique)
- Stratégie d'échantillonnage et origine des textes (genre)
- Modalité (écrit/oral)
- Licence et droits d'utilisation

&rarr; Tout ça se trouve dans la carte des corpus

-vertical-

✏️Quiz Time✏️

-horizontal-

## 🔎Où trouver des corpus🔍

&rarr; Quand on sait quoi chercher, on peut commencer à requêter
- [HuggingFace](https://huggingface.co/)
- [Kaggle](https://www.kaggle.com/)
- [PapersWithCode](https://paperswithcode.com/)

-vertical-

## 🔎Où trouver des corpus🔍

- Agences de distribution
- [Linguistic Data Consortium](https://www.ldc.upenn.edu/)
- [ELRA](http://www.elra.info/ )
- Inventaires et portails
- [LRE Map](http://lremap.elra.info/)
- [VLO](http://catalog.clarin.eu/vlo/)
- [CHILDES](https://childes.talkbank.org/)
- [Ortolang](http://www.ortolang.fr/)

(cf. [Clement Plancq](https://clement-plancq.github.io/outils-corpus/outils_corpus-1.html#/o%C3%B9-trouver-les-corpus))

-vertical-

### 💂Les grands corpus de l'anglais💂

- Text Classification
- IMDB
- GLUE
- Token Classification
- conll
- Question Answering
- MMLU
- thruful_qa
- Summarization
- cnn_dailymail
- scientific_papers

-vertical-

<h3 class="r-fit-text">🥖Les grands corpus du français🥖</h3>


- frWaC (1,6 milliards de mots, annotation POS avec TreeTagger)
- FRCOW16 (8,7 milliards de mots)
- OSCAR (23 milliards de mots pour le français (issu de Common Crawl))
(cf. [Clement Plancq](https://clement-plancq.github.io/outils-corpus/outils_corpus-1.html#/les-gros-corpus-du-web))

-horizontal-

## Petit Récap'

- On sait à quoi ça sert d'avoir beaucoup de données
- On sait où les trouver
- On sait déterminer de quoi on a besoin en fonction de la tâche qu'on veut réaliser

-vertical-

❓ Des questions ❓

💡 Des idées 💡

-vertical-

## Le point Bonne Pratique

Git❤️ nécessite quelques bonne pratiques

&rarr; On ne commit pas sur le main

&rarr; On respecte les [commits conventionnels](https://www.conventionalcommits.org/en/v1.0.0/) (un lien en
français[ici](https://buzut.net/cours/versioning-avec-git/bien-nommer-ses-commits))

&rarr; On fait un commit par changement et on garde le tout clair

&rarr; ON NE COMMIT PAS LES GROS FICHIERS (il faut les mettre dans le `.gitignore` ou les commit autrement si c'est
absolument nécessaire)

-vertical-

<p class="r-fit-text">
<ol>
    <li>Initialiser votre repo github et envoyer le lien à mon adresse mail</li>
    <li>Initialiser votre README.md</li>
    <ul>
        <li>Avec la tâche que vous voulez réaliser</li>
        <li>un corpus qui répond à cette tâche</li>
        <li>à quel type de prédiction peut servir ce corpus</li>
        <li>à quel modèle il a servi</li>
        <li>Apprenez moi des choses sur un corpus</li>
    </ul>
</ol>
Et le tout avec des beaux messages de commit 🔥
</p>

-vertical-
### Correction

**tâche** : Question Answering
-> Tâche de prédiction d'une réponse à partir d'une question

**sous-tâche** : extractive-qa
-> Q&A à partir d'un contexte : le modèle ne doit extraire la réponse que du contexte qu'on lui donne

**type de tâche :** Classif ?

**Corpus :** SQuAD : Stanford QUestion Answering Dataset

**Langues :** Anglais, uniquement
-> D'autres corpus existent dans d'autres langues, lesquels ?

Le corpus comporte les informations suivantes : **id, title, context, question, answers**

**id :** Un champ unique pour distinguer une suite d'information

**title :** Le titre