---
layout: presentation
title: Cours1
---
# Outils de Traitement de Corpus
👩Eve Sauvage👩

📫eve.sauvage at lisn dot fr📪

🌐[EveSa.github.io/OutilsTraitementCorpus](EveSa.github.io/OutilsTraitementCorpus)🌐

<aside class="notes">
    Vous m'appelez Eve et on se tutoie si vous n'avez pas d'objection -> Je connais certains d'entre vous et je viens de terminer ce master.
    Je ne suis pas une figure hierarchique.
</aside>

-vertical-
## Organisation du Cours

📅6 x 3 heures📅

⏱️ 3 parties: ⏱️

<sup><sub>- cours magistral</sub></sup>

<sup><sub>- retours et questions</sub></sup>

<sup><sub>- TP</sub></sup>

🏫en amphi 3🏫

<aside class="notes">
    Profitez de la partie retour pour me dire les notions que vous souhaiterez voir aborder
    Les points, même des autres cours que vous n'avez peut être pas compris
    etc...
</aside>

-vertical-

<p>les slides sont dispo en ligne et vous pouvez les convertir au format pdf en imprimant la présentation🖨️</p>

`ctrl+P` &rarr; imprimer au format pdf

<aside class="notes">
    L'objectif c'est que vous ne soyez pas obligés de venir en cours pour Suivre
    Ne prenez pas de photo des slides, ne copiez pas frénétiquement ce qu'il y a écrit
    Ne venez pas faire du bruit inutilement, ça ne me dérange pas que vous ne soyez pas là
    ça ne veut pas dire "ne venez pas". Je suis là pour
    - éclaircir les points qui ne vous paraissent pas clair
    - répondre à vos questions
</aside>

-vertical-
## Evaluation

<p class="r-fit-text">📚📄Evaluation de corpus au cours d'un projet en 6 séances📄📚</p>

A rendre sur Git

<aside class="notes">
-> pourquoi je vous fais rendre sur Github ❓ 

- les (bons) recruteurs regardent votre github avant votre CV
- les (bons) chercheurs regardent le github avant les papiers
- Si vous faites des boulettes, vous êtes pas perdus

-> Les critères d'évaluation:
- surtout le respect des bonnes problématiques
- et ensuite si vous avez effectué le travail demandé
</aside>

-horizontal-
# Cours 1
<h2 class="r-fit-text">📚📄Rappels sur les corpus📚📄</h2>

## 🛠️Focus sur les tâches🛠️
## 🔎Où trouver des corpus🔍

-vertical-
### 📄📚Qu'est ce qu'un corpus📚📄
<!--normalement vous savez ce que c'est-->

- Une collection de documents
- Sur un thème particulier
- Pour une tâche particulière

---
Avant de revenir sur ces caractéristiques :

<aside class="notes">
    les documents peuvent être de nature différentes :
        - texte
        - image
        - son
</aside>

-vertical-
<h3 class="r-fit-text">❓A quoi ça sert les données❓</h3>

**Pour la linguistique**

Pour vérifier des hypothèses ou inférer des comportements linguistiques

**Pour la littérature**

Realiser des statistiques textuelles

-vertical-
<h3 class="r-fit-text">❓A quoi ça sert les données❓</h3>

**Pour l'apprentissage**

à partir des observations (*données*), on peut déterminer des paramètres (*features*) qui vont nous permettre de prédire le futur

<img src =https://www.baeldung.com/wp-content/uploads/sites/4/2022/03/1_latent-1024x307.png alt="latent space">

-vertical-

**un exemple (simpliste)*

⛅Comment savoir comment s'habiller demain ?⛅:
- la saison ❄🌺
- la couverture nuageuse de la journée précédente ☁
- le vent 🍃
- la météo des régions voisines 🌍
- ...

Comment on en est arrivé à ces conclusions ? ➡️ les observations
<p class="fragment r-fit-text">Un exemple plus linguistique &rarr; l'acquisition du language chez les enfants</p>

<aside class="notes">
    C'est une représentation simpliste pour vous aider à comprendre comment ça fonctionne
    On ne prédit pas la météo avec des paramètres aussi simples
    Est-ce que vous voyez une meilleur exemple de chose à prévoir qui soit en lien avec le NLP?
</aside>

-vertical-

<h3 class="r-fit-text">🤖Pour les machines, c'est pareil🤖</h3>

On a besoin de **données** pour apprendre les **paramètres** qui permettent de prédire le futur

&rarr; On collecte des corpus (*datasets*)

C'est comme ça qu'on obtient des modèles **prédictifs**

-vertical-

## On peut maintenant revenir sur les caractéristiques de notre corpus📚📄

-vertical-

### Une collection = un nombre représentatif de données

**Pour couvrir suffisamment de cas**

---

⛅Prévoir la météo⛅

- nuage ☁ = pluie 🌧
- vent 🍃 = beau temps &#9728;&#65039;
- nuage ☁ + vent 🍃 = ❓

-vertical-

### Un thème

**Pour éviter le bruit**

---

⛅Prévoir la météo⛅

- mon humeur de ce matin 🎭
- le nombre de café que j'ai bu ☕
- les traces de bouctins devant chez moi 👣
- ...

-vertical-

### Pour une tâche donnée

**Pour avoir la sortie voulue**

---

| | |   
|:---:|:---:|
| ❄🌺 | ❄🌺 |
| ☁ | ☁ |
| ... | ... |
|&rarr; |&rarr; |
|⛅Prédire la météo⛅|🦜Parler de la pluie et du beau temps🦜|

-vertical-

### ❓ A quel point c'est important ❓
<!-- Pourquoi on vous parle de corpus tout le temps ?
    Corpus Parallèle et Comparable / Outils de traitement de corpus / Enrichissement de corpus / ...
-->
C'est le nerf de la guerre

Les entreprises publient :

✔️ 🏠 les architectures

✔️ 🔩 les poids des modèles

❌ 📚 mais pas les données

-vertical-

### Obtenir des données

&rarr; Avec internet, c'est plus si compliqué

### Obtenir des données *utiles*

&rarr; C'est très couteux 💸💸💸

-vertical-

### Les problématiques des données

- La propreté des données ✨
    - quand on récupère les données sur internet, on a de tout

- L'annotation des données🏷️
    - Pour réaliser certaines annotations, on a besoin d'experts et ça coûte cher

-vertical-

### Les problématiques des données

- Le RGPD 🕵️‍♂️
    - particulièrement visible dans le domaine médical &rarr; alors que les modèles sont très bons pour prédire les pathologies

- La représentativité des données
    - Les données peuvent être biaisées &rarr; avoir des caractéristiques qu'on voudrait éviter

-horizontal-

<h2 class="r-fit-text">🛠️Les tâches et les corpus🛠️</h2>

En *Machine Learning*, on fait de la prédiction :

- pour catégoriser les éléments existants (classification)
- pour découvrir de nouveaux éléments (regression)

❓ Qu'en est-il de prédire la météo de demain ❓

<aside class="notes">
    Quand vous décidez comment vous habillez le matin/pour prévoir la météo, vous faites quel type de prédiction ?
    Levez la main haut pour réponse 1 et la main pas trop haut pour réponse 2
    (la bonne réponse c'est réponse 2)
</aside>

-vertical-

<img src="https://miro.medium.com/v2/resize:fit:1400/1*xs6Jr4iAPvoqszF9JgDWOA.png">

-vertical-

<h3 class="r-fit-text">🏷️Catégorisation d'éléments existants en NLP🏷️</h3>

- POS tagging
- Analyse de sentiment
- NER
- Transcription
- ...

-vertical-

<h3 class="r-fit-text">🌱Génération de nouveaux éléments en TAL🌱</h3>

❓

<p class="fragment">On a pas beaucoup de tâche de régression en TAL</p>

-vertical-

<h3>Et la génération de texte ❓</h3>

⚠️En TAL, la génération de nouveaux éléments, ce n'est souvent pas de la régression

- Chatbot
- QuestionAnswering
- Traduction
- Résumé Automatique
- ...

&rarr; Tout ça, ce sont des tâches de *Next-Token Prediction*

-vertical-

<h3>Comment se passe la NTP</h3>

<img src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/06/general-workflow-for-prompt.png">

-vertical-

### Avant de sélectionner son corpus

<div class="r-stack">

&rarr; bien déterminer la tâche que l'on veut traiter :

- son besoin en ressources
    - quel modèle on utilise ? *Machine Learning*/*Deep Leaning* ?
- les langues que l'on va traiter
    - monolingue/multilingue
    - traduction ? (corpus Parallèle)
- le genre des textes
    - ex : résumé d'article de journaux vs. résumé de décision de justice

<img class="fragment fade-in-then-out" src ="https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png">
</div>

-vertical-


### Critères de définition d'un corpus

- Taille (en nb de mots le plus souvent)
- Annotations (niveaux et outils utilisés)
- Statut de la documentation (guidelines, publication scientifique)
- Stratégie d'échantillonnage et origine des textes (genre)
- Modalité (écrit/oral)
- Licence et droits d'utilisation

-horizontal-

## 🔎Où trouver des corpus🔍

&rarr; Quand on sait quoi chercher, on peut commencer à requêter
- [HuggingFace](https://huggingface.co/)
- [Kaggle](https://www.kaggle.com/)
- [PapersWithCode](https://paperswithcode.com/)

-vertical-

## 🔎Où trouver des corpus🔍

- Agences de distribution
    - [Linguistic Data Consortium](https://www.ldc.upenn.edu/)
    - [ELRA](http://www.elra.info/ )
- Inventaires et portails
    - [LRE Map](http://lremap.elra.info/)
    - [VLO](http://catalog.clarin.eu/vlo/)
    - [CHILDES](https://childes.talkbank.org/)
    - [Ortolang](http://www.ortolang.fr/)

(cf. [Clement Plancq](https://clement-plancq.github.io/outils-corpus/outils_corpus-1.html#/o%C3%B9-trouver-les-corpus))

-vertical-

### 💂Les grands corpus de l'anglais💂

- Text Classification
    - IMDB
    - GLUE
- Token Classification
    - conll
- Question Answering
    - MMLU
    - thruful_qa
- Summarization
    - cnn_dailymail
    - scientific_papers

-vertical-

<h3 class="r-fit-text">🥖Les grands corpus du français🥖</h3>


- frWaC (1,6 milliards de mots, annotation POS avec TreeTagger)
- FRCOW16 (8,7 milliards de mots)
- OSCAR (23 milliards de mots pour le français (issu de Common Crawl))
(cf. [Clement Plancq](https://clement-plancq.github.io/outils-corpus/outils_corpus-1.html#/les-gros-corpus-du-web))

-horizontal-

## Petit Récap'

- On sait à quoi ça sert d'avoir beaucoup de données
- On sait où les trouver
- On sait déterminer de quoi on a besoin en fonction de la tâche qu'on veut réaliser

-vertical-

❓ Des questions ❓

💡 Des idées 💡

-vertical-

## Le point Bonne Pratique

Git❤️ nécessite quelques bonne pratiques

&rarr; On ne commit pas sur le main

&rarr; On respecte les [commits conventionnels](https://www.conventionalcommits.org/en/v1.0.0/)

&rarr; On fait un commit par changement et on garde le tout clair

&rarr; ON NE COMMIT PAS LES GROS FICHIERS (il faut les mettre dans le `.gitignore` ou les commit autrement si c'est absolument nécessaire)

-vertical-

<p class="r-fit-text">
<ol>
<li>Initialiser votre repo github et envoyer le lien à mon adresse mail</li>
<li>Initialiser votre README.md</li>
<ul>
    <li>Avec la tâche que vous voulez réaliser</li>
    <li>un corpus qui répond à cette tâche</li>
    <li>à quel type de prédiction peut servir ce corpus</li>
    <li>à quel modèle il a servi</li>
    <li>Apprenez moi des choses sur un corpus</li>
</ul>
</ol>
Et le tout avec des beaux messages de commit 🔥
</p>
