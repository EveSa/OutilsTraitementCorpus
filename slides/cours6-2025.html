---
title: cours6
layout: presentation
---

# Outils de traitement de corpus

-vertical-

## Cours 6

-vertical-

**Correction des quizz**

<div class="r-fit-text">
1. Calculez l'entropie de la distribution suivante : probabilit√© de l'√©v√®nement A (0,6) ; probabilit√© de l'√©v√®nement B (0,2) ; probabilit√© de l'√©v√®nement C (0,2)

&rarr; $-(0,6*log_2(0,6)*2*(0,2*log_2(0,2))) = 1,37$

C'est √† dire qu'il faut en moyenne 1,37 questions pour r√©soudre l'incertitude de cette distribution

2. Vous avez m√©lang√© tous les exemples de l'ensemble de donn√©es et les avez divis√©s en ensembles d'entra√Ænement, de validation et de test. Cependant, la valeur de loss sur votre ensemble de test est si faible que vous suspectez une erreur. Qu'est-ce qui a pu se passer ?

&rarr; Si les performances de mon mod√®le sont trop bonnes, je peux avoir contamin√© mon ensemble de test avec des donn√©es entra√Ænement notamment √† cause de donn√©es dupliqu√©es dans le jeu de donn√©es original par exemple.
</div>

-vertical-

1. Quel mod√®le utiliser pour trouver les caract√©ristiques des donn√©es suivantes : 

&rarr; on utilise un mod√®le de regression lin√©aire avec une loss MSE ou MAE par exemple.

-vertical-
2. Calculez la descente de gradient du mod√®le $f(x)=w*x+b$ avec une Perte L2 √©crite $sum(valeur\ r√©elle-valeur\ pr√©dite)^2$

<div class="r-fit-text">

&rarr; Pour faire une descente de gradient, il faut d'abord calculer la loss de la fonction. On calcule ensuite la d√©riv√©e de la fonction.

Ici, notre fonction est : `$\sum{y-(w*x+b)}^2$` . On va calculer sa d√©riv√©e selon $w$. On est sous la forme `$\diff{f}{x}=f \circ g(x) = f(g(x))'*g(x)'$` avec `$g=\(y-(w*x+b))$` et `$f(g)=g^2$` car on peut ignorer la somme (car la d√©riv√©e de la somme est la somme des d√©riv√©es), donc `$\diff{}{x}(y-(w*x+b))^2 = 2(y-w*x+b)*x$`. On calcule cette d√©riv√©e sur nos exmples ce qui nous donne une direction vers laquelle d√©placer les poids pour x.

</div>

-vertical-
3. A quoi sert une taille de lot (batch) importante ?

&rarr; On calcule le gradiant de la loss sur un ensemble de donn√©es qu'on appelle *batch*. Plus le *batch* est grand, plus la direction dans laquelle on va deplacer les poids va √™tre pertinente (car elle prendra en compte toutes les informations du jeu de donn√©es). Avoir une taille de batch importante permet donc un meilleur apprentissage. Toutefois, le nombre de calculs n√©cessaire pour traiter tout le jeu de donn√©es √©tant tr√®s important, on limite souvent la taille de **batch** a des petites valeurs pour ne pas sur-utiliser la m√©moire des machines.

-vertical-

### Newsletter

-horizontal-

## Cours 6

## Evaluations

- de mod√®le

- de corpus

-vertical-

### Courbe de loss

On a vu la derni√®re fois que pour entra√Æner notre mod√®le, il √©tait imp√©ratif de minimiser la valeur de la fonction de perte.

Mais il faut √©galement evaluer son mod√®le sur notre jeu de donn√©es de test pour v√©rifier sa performance hors de nos donn√©es d'entra√Ænement.

-vertical-

On a parl√© des fonctions de perte pour les regressions lin√©raire : MSE, MAE, etc...

Mais qu'en est-il de la classification ?

-vertical-

### M√©triques de classification

Les vrais et faux positifs et n√©gatifs sont utilis√©s pour calculer plusieurs m√©triques utiles pour l'√©valuation des mod√®les. Les m√©triques d'√©valuation les plus pertinentes d√©pendent du mod√®le et de la t√¢che sp√©cifiques, du co√ªt des diff√©rentes erreurs de classification, et si l'ensemble de donn√©es est √©quilibr√© ou d√©s√©quilibr√©.

Toutes les m√©triques sont calcul√©es selon un seul seuil fixe et changent lorsque ce seuil change. Tr√®s souvent, l'utilisateur ajuste le seuil pour optimiser l'une de ces m√©triques.

-vertical-

**Accuracy**

L'accuracy est la proportion de toutes les classifications qui √©taient correctes, qu'elles soient positives ou n√©gatives. Il est d√©fini math√©matiquement comme suit :

<div class="r-fit-text">
$\text{Accuracy} =
\frac{\text{correct classifications}}{\text{total classifications}}
= \frac{TP+TN}{TP+TN+FP+FN}$

Dans l'exemple de classification du spam, la justesse mesure la fraction de tous les e-mails correctement class√©s.

Un mod√®le parfait ne comporterait aucun faux positif ni aucun faux n√©gatif, et aurait donc une pr√©cision de 1,0, soit 100 %.
</div>

-vertical-

√âtant donn√© qu'elle int√®gre les quatre r√©sultats de la matrice de confusion (VP, FP, VN, FN), pour un ensemble de donn√©es √©quilibr√©, avec un nombre d'exemples similaire dans les deux classes, l'accuracy peut servir de mesure grossi√®re de la qualit√© du mod√®le. C'est pourquoi il s'agit souvent de la m√©trique d'√©valuation par d√©faut utilis√©e pour les mod√®les g√©n√©riques ou non sp√©cifi√©s effectuant des t√¢ches g√©n√©riques ou non sp√©cifi√©es.

-vertical-

Toutefois, lorsque l'ensemble de donn√©es est d√©s√©quilibr√© ou qu'un type d'erreur (FN ou FP) est plus co√ªteux que l'autre, ce qui est le cas dans la plupart des applications r√©elles, il est pr√©f√©rable d'optimiser pour l'une des autres m√©triques.

Pour les ensembles de donn√©es tr√®s d√©s√©quilibr√©s, o√π une classe appara√Æt tr√®s rarement, disons 1 % du temps, un mod√®le qui pr√©dit une valeur n√©gative 100 % du temps obtiendrait un score de justesse de 99 %, bien qu'il soit inutile.

-vertical-

**Rappel ou taux de vrais positifs**

Le taux de vrais positifs (TVP), ou la proportion de tous les r√©sultats positifs r√©els qui ont √©t√© correctement class√©s comme tels, est √©galement appel√© rappel.

Math√©matiquement, le rappel est d√©fini comme suit :

<div class="r-fit-text">
$\text{Recall (or TPR)} =
\frac{\text{correctly classified actual positives}}{\text{all actual positives}}
= \frac{TP}{TP+FN}$
</div>

-vertical-

Les faux n√©gatifs sont des √©l√©ments positifs r√©els qui ont √©t√© class√©s √† tort comme n√©gatifs. C'est pourquoi ils apparaissent dans le d√©nominateur. Dans l'exemple de classification du spam, le rappel mesure la fraction d'e-mails de spam correctement class√©s comme spam. C'est pourquoi le rappel est √©galement appel√© probabilit√© de d√©tection : il r√©pond √† la question "Quelle fraction des e-mails de spam sont d√©tect√©s par ce mod√®le ?".

-vertical-

Un mod√®le parfait hypoth√©tique ne comporterait aucun faux n√©gatif et aurait donc un rappel (TPR) de 1,0, c'est-√†-dire un taux de d√©tection de 100 %.

Dans un ensemble de donn√©es d√©s√©quilibr√© o√π le nombre de r√©sultats positifs r√©els est tr√®s, tr√®s faible (par exemple, un √† deux exemples au total), le rappel est moins pertinent et moins utile en tant que m√©trique.

-vertical-

**Taux de faux positifs**

Le taux de faux positifs (FPR) est la proportion de tous les n√©gatifs r√©els qui ont √©t√© incorrectement class√©s comme positifs. Il est √©galement appel√© probabilit√© de fausse alarme. Il est d√©fini math√©matiquement comme suit :

<div class="r-fit-text">
$\text{FPR} =
\frac{\text{incorrectly classified actual negatives}}
{\text{all actual negatives}}
= \frac{FP}{FP+TN}$
</div>

-vertical-

Les faux positifs sont des n√©gatifs r√©els qui ont √©t√© mal class√©s. C'est pourquoi ils apparaissent au d√©nominateur. Dans l'exemple de classification du spam, le FPR mesure la fraction d'e-mails l√©gitimes class√©s √† tort comme spam, ou le taux de fausses alarmes du mod√®le.

-vertical-

Un mod√®le parfait ne comporterait aucun faux positif et donc un taux de faux positifs de 0,0, c'est-√†-dire un taux de fausses alarmes de 0 %.

Dans un ensemble de donn√©es d√©s√©quilibr√© o√π le nombre de n√©gatifs r√©els est tr√®s, tr√®s faible (par exemple, un √† deux exemples au total), la FPR est moins pertinente et moins utile en tant que m√©trique.

-vertical-

Pr√©cision
La pr√©cision correspond √† la proportion de toutes les classifications positives du mod√®le qui sont r√©ellement positives. Elle est d√©finie math√©matiquement comme suit:

<div class="r-fit-text">
$\text{Precision} =
\frac{\text{correctly classified actual positives}}
{\text{everything classified as positive}}
= \frac{TP}{TP+FP}$
</div>

-vertical-

Dans l'exemple de classification du spam, la pr√©cision mesure la fraction des e-mails class√©s comme spam qui √©taient effectivement du spam.

Un mod√®le parfait hypoth√©tique ne comporterait aucun faux positif et aurait donc une pr√©cision de 1,0.

Dans un ensemble de donn√©es d√©s√©quilibr√© o√π le nombre de r√©sultats positifs r√©els est tr√®s, tr√®s faible (par exemple, un √† deux exemples au total), la pr√©cision est moins pertinente et moins utile en tant que m√©trique.

-vertical-

La pr√©cision s'am√©liore √† mesure que les faux positifs diminuent, tandis que le rappel s'am√©liore lorsque les faux n√©gatifs diminuent. Toutefois, comme nous l'avons vu dans la section pr√©c√©dente, l'augmentation du seuil de classification a tendance √† r√©duire le nombre de faux positifs et √† augmenter le nombre de faux n√©gatifs, tandis que la diminution du seuil a les effets inverses. Par cons√©quent, la pr√©cision et le rappel pr√©sentent souvent une relation inverse, o√π l'am√©lioration de l'un d√©grade l'autre.

-vertical-

**Choix de la m√©trique et compromis**

La ou les m√©triques que vous choisissez de prioriser lors de l'√©valuation du mod√®le et du choix d'un seuil d√©pendent des co√ªts, des avantages et des risques du probl√®me sp√©cifique. Dans l'exemple de classification du spam, il est souvent judicieux de donner la priorit√© au rappel, en d√©tectant tous les e-mails de spam, ou √† la pr√©cision, en s'assurant que les e-mails marqu√©s comme spam sont en fait du spam, ou √† un √©quilibre entre les deux, au-dessus d'un certain niveau de pr√©cision minimal.

-vertical-

<table style="border:1px solid #dadce0" class="r-fit-text">
    <tbody><tr style="border:1px solid #dadce0">
      <th style="text-align:center;border:1px solid #dadce0">M√©trique</th>
      <th style="text-align:center;border:1px solid #dadce0">Conseils</th>
    </tr>
    <tr style="border:1px solid #dadce0">
      <td style="border:1px solid #dadce0">Accuracy</td>
      <td style="border:1px solid #dadce0"><p>√Ä utiliser comme indicateur approximatif de la progression/convergence de l'entra√Ænement du mod√®le pour les ensembles de donn√©es √©quilibr√©s.</p>
      <p>Pour optimiser les performances du mod√®le, n'utilisez cette option qu'avec d'autres m√©triques.</p>
      <p>√Ä √©viter pour les ensembles de donn√©es d√©s√©quilibr√©s. Envisagez d'utiliser une autre m√©trique.</p></td>
    </tr>
    <tr style="border:1px solid #dadce0">
      <td style="border:1px solid #dadce0">Rappel<br \=""> (taux de vrais positifs)</td>
      <td style="border:1px solid #dadce0">√Ä utiliser lorsque les faux n√©gatifs sont plus co√ªteux que les faux positifs.</td>
    </tr>
    <tr style="border:1px solid #dadce0">
      <td style="border:1px solid #dadce0">Taux de faux positifs</td>
      <td style="border:1px solid #dadce0">√Ä utiliser lorsque les faux positifs sont plus co√ªteux que les faux n√©gatifs.</td>
    </tr>
    <tr style="border:1px solid #dadce0">
      <td style="border:1px solid #dadce0">Pr√©cision</td>
      <td style="border:1px solid #dadce0">√Ä utiliser lorsque la pr√©cision des pr√©dictions positives est tr√®s importante.</td>
    </tr>
  </tbody></table>

-vertical-

**Score F1**

Le score F1 correspond √† la moyenne harmonique (une sorte de moyenne) de la pr√©cision et du rappel.

Math√©matiquement, elle est calcul√©e comme suit:

$\text{F1}=2*\frac{\text{precision * recall}}{\text{precision + recall}}
  = \frac{2\text{TP}}{2\text{TP + FP + FN}}$

-vertical-

Cette m√©trique √©quilibre l'importance de la pr√©cision et du rappel, et est pr√©f√©rable √† la pr√©cision pour les ensembles de donn√©es d√©s√©quilibr√©s. Lorsque la pr√©cision et le rappel atteignent tous deux un score parfait de 1,0, le score F1 est √©galement parfait, soit 1,0. Plus g√©n√©ralement, lorsque la valeur de pr√©cision et de rappel est proche, F1 est proche de leur valeur. Lorsque la pr√©cision et le rappel sont tr√®s √©loign√©s, le score F1 est semblable √† la m√©trique la moins bonne.

-vertical-

**Courbe ROC (Receiver Operating Characteristic)**

<div class="r-fit-text">
La courbe ROC est une repr√©sentation visuelle des performances du mod√®le pour tous les seuils. La version longue du nom, "Receiver Operating Characteristic" (caract√©ristique op√©rationnelle du r√©cepteur) est une retenue des syst√®mes de d√©tection de radars de la Seconde Guerre mondiale.

La courbe ROC est dessin√©e en calculant le taux de vrais positifs (TPR). et de faux positifs pour chaque seuil possible (en pratique, des intervalles s√©lectionn√©s), puis le TPR et le TFP. Un mod√®le parfait, qui, √† un certain seuil, a un TVP de 1,0 et 0,0, √™tre repr√©sent√© par un point en (0, 1) si tous les autres seuils sont ignor√©s, ou par:
</div>

<img class="r-stretch" src="https://developers.google.com/static/machine-learning/crash-course/images/auc_1-0.png?hl=fr">

-vertical-

**Aire sous la courbe (AUC)**

<div class="r-fit-text">
L'aire sous la courbe ROC (AUC) repr√©sente la probabilit√© que le mod√®le, si un exemple positif et n√©gatif est choisi al√©atoirement, classera positive sup√©rieure √† la n√©gative.

Le mod√®le parfait ci-dessus, qui contient un carr√© dont les c√¥t√©s font 1, a une sous la courbe (AUC) de 1,0. Cela signifie qu'il y a une probabilit√© de 100% que le mod√®le classe correctement un exemple positif choisi al√©atoirement au-dessus d'un exemple n√©gatif choisi al√©atoirement. En d'autres termes, examiner la propagation points de donn√©es ci-dessous, l'AUC donne la probabilit√© que le mod√®le place carr√© choisi al√©atoirement √† droite d'un cercle choisi al√©atoirement, ind√©pendamment de o√π le seuil est d√©fini.
</div>

-vertical-

Plus concr√®tement, un classificateur de spam avec AUC de 1.0 attribue toujours une probabilit√© plus √©lev√©e √† un spam de spam qu'un e-mail l√©gitime al√©atoire. La classification r√©elle de chaque d√©pend du seuil que vous choisissez.

Pour un classificateur binaire, un mod√®le qui r√©alise aussi bien des suppositions al√©atoires dont la valeur ROC correspond √† une ligne diagonale comprise entre (0,0) et (1,1). L'AUC est 0,5, ce qui repr√©sente une probabilit√© de 50% de classer correctement un positif al√©atoire et exemple n√©gatif.

-vertical-

Dans l'exemple du classificateur de spam, un classificateur de spam avec une AUC de 0,5 attribue un spam al√©atoire a plus de chances d'√™tre ind√©sirable qu'un les e-mails l√©gitimes seulement une fois la moiti√© du temps.

<img class="r-stretch" src="https://developers.google.com/static/machine-learning/crash-course/images/auc_0-5.png?hl=fr"/>

-vertical-

<div class="r-fit-text">
Les valeurs AUC et ROC sont efficaces pour comparer des mod√®les lorsque l'ensemble de donn√©es entre les classes. Lorsque l'ensemble de donn√©es est d√©s√©quilibr√©, la pr√©cision/rappel (PRC) et l'aire sous ces courbes peut offrir un meilleur r√©sultat des performances du mod√®le. Les courbes de pr√©cision/rappel sont cr√©√©es la pr√©cision du trac√© sur l'axe des y et le rappel sur l'axe des x sur toutes de s√©curit√©.
</div>

<img class="r-stretch" src="https://developers.google.com/static/machine-learning/crash-course/images/prauc.png?hl=fr"/>

-vertical-

**AUC et ROC pour choisir le mod√®le et le seuil**

<div class="r-fit-text">
L'AUC est une mesure utile pour comparer les performances de deux mod√®les diff√©rents, √† condition que l'ensemble de donn√©es soit √† peu pr√®s √©quilibr√©. (voir Courbe de pr√©cision/rappel, (voir ci-dessus, pour les ensembles de donn√©es d√©s√©quilibr√©s). Le mod√®le dont l'aire sous la plus grande la courbe est g√©n√©ralement la meilleure.
</div>

<img class="r-stretch" src="https://developers.google.com/static/machine-learning/crash-course/images/auc_0-65.png"/>

-vertical-

<div class="r-fit-text">
Les points d'une courbe ROC les plus proches de (0,1) repr√©sentent une plage de les seuils les plus performants pour le mod√®le donn√©. Comme indiqu√© dans le Seuils Matrice de confusion et Choix de la m√©trique et compromis le seuil que vous choisissez d√©pend de la m√©trique la plus importante pour un cas d'utilisation sp√©cifique. Examinez les points A, B et C dans les chacun repr√©sentant un seuil:
</div>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/auc_abc.png" class="r-stretch"/>

-vertical-

Si les faux positifs (fausses alarmes) sont tr√®s co√ªteux, il peut √™tre judicieux de Choisissez un seuil offrant un TFP inf√©rieur, comme celui du point A, m√™me si est r√©duite. Inversement, si les faux positifs sont bon march√© et les faux n√©gatifs (vrais positifs manqu√©s) tr√®s co√ªteux, le seuil du point C, qui maximise le TVI, ce qui peut √™tre pr√©f√©rable. Si les co√ªts sont √† peu pr√®s √©quivalents, point B peut offrir le meilleur √©quilibre entre le TVP et le TFP.

-vertical-

Quizz 1

-vertical-

<div class="r-fit-text">
1. Un mod√®le g√©n√®re 5 VP, 6 VN, 3 FP et 2 FN. Calculez le rappel.

2. Imaginez une situation o√π il est pr√©f√©rable de laisser du spam arriver dans la bo√Æte de r√©ception plut√¥t que d'envoyer un e-mail critique vers le dossier spam. Vous avez entra√Æn√© un classificateur de spam pour cette situation, o√π la classe positive est le spam et la classe n√©gative le non-spam. Lequel des points suivants de la courbe ROC de votre classificateur est pr√©f√©rable¬†?
</div>

<img class="r-stretch" src="https://developers.google.com/static/machine-learning/crash-course/images/auc_abc.png"/>

-horizontal-

**Classification¬†: Biais de pr√©diction**

<div class="r-fit-text">
Le calcul du biais de pr√©diction est une v√©rification rapide qui permet de d√©tecter rapidement des probl√®mes avec le mod√®le ou les donn√©es d'entra√Ænement.

Le biais de pr√©diction est la diff√©rence entre la moyenne des pr√©dictions d'un mod√®le et la moyenne des √©tiquettes de r√©f√©rence dans les donn√©es. Un mod√®le entra√Æn√© sur un ensemble de donn√©es contenant 5¬†% de ses e-mails comme spam devrait pr√©dire, en moyenne, que 5¬†% des e-mails qu'il classe comme spam. Autrement dit, la moyenne des √©tiquettes de l'ensemble de donn√©es de r√©f√©rence est de 0,05, et la moyenne des pr√©dictions du mod√®le devrait √©galement √™tre de 0,05. Si tel est le cas, le mod√®le pr√©sente un biais de pr√©diction nul. Bien entendu, d'autres probl√®mes peuvent subsister.
</div>

-vertical-

Si, au contraire, le mod√®le pr√©dit qu'un e-mail est spam dans 50¬†% des cas, il y a un probl√®me avec l'ensemble de donn√©es d'entra√Ænement, le nouvel ensemble de donn√©es auquel le mod√®le est appliqu√© ou le mod√®le lui-m√™me. Toute diff√©rence significative entre les deux moyennes sugg√®re que le mod√®le pr√©sente un biais de pr√©diction.

-vertical-

Un biais de pr√©diction peut √™tre caus√© par¬†:

- Des biais ou du bruit dans les donn√©es, notamment un √©chantillonnage biais√© pour l'ensemble d'apprentissage¬†;
- Une r√©gularisation trop forte, ce qui signifie que le mod√®le a √©t√© trop simplifi√© et a perdu une partie de sa complexit√© n√©cessaire¬†;
- Des bugs dans le pipeline d'apprentissage du mod√®le¬†;
- L'ensemble de fonctionnalit√©s fournies au mod√®le est insuffisant pour la t√¢che.

-vertical-

**M√©triques d'evaluation pour le TAL**

<div class="r-fit-text">
Toutes les m√©triques pr√©sent√©es pr√©cedemment sont tr√®s globale au machine learning. Mais le TAL a certaines sp√©cificit√©es qui demandent des m√©triques d'√©valuation sp√©cifiques.

Les indicateurs d'√©valuation du TALN √©valuent les performances des mod√®les dans diff√©rentes t√¢ches. Ces indicateurs permettent de d√©terminer la capacit√© d'un mod√®le √† comprendre, g√©n√©rer ou traiter le langage humain.

Le choix de l'indicateur d'√©valuation d√©pend de la t√¢che TAL sp√©cifique, comme la classification de texte, la traduction automatique ou la synth√®se de texte.
</div>

-vertical-

On distingue souvent les m√©thodes d'√©valuations en plusieurs types :

- intrins√®ques vs. extrins√®ques
- formatives vs. sommatives

-vertical-

**Formatives/Sommatives**

Les √©valuations formatives interviennent g√©n√©ralement lors du d√©veloppement des syst√®mes de TALN. Leur objectif principal est d'informer le concepteur des progr√®s r√©alis√©s vers les objectifs vis√©s. De ce fait, les √©valuations formatives ont tendance √† √™tre l√©g√®res (afin de permettre une √©valuation rapide) et it√©ratives (afin que les retours d'exp√©rience puissent √™tre int√©gr√©s ult√©rieurement pour am√©liorer le syst√®me). 

-vertical-

En revanche, les √©valuations sommatives sont g√©n√©ralement r√©alis√©es une fois le syst√®me termin√© (ou ayant franchi une √©tape importante de son d√©veloppement)¬†: elles visent √† √©valuer si les objectifs vis√©s ont √©t√© atteints.

Les √©valuations formatives ont tendance √† √™tre automatiques,
afin de fournir un retour d'exp√©rience rapide tout au long du processus de d√©veloppement. En revanche, les √©valuations sommatives font souvent appel √† des juges humains, afin d‚Äô√©valuer l‚Äôutilit√© du syst√®me dans son ensemble pour les utilisateurs.

-vertical-

**Intrins√®que/Extrins√®que**

<div class="r-fit-text">
√âvaluation intrins√®que¬†: se concentre sur les performances internes du mod√®le, souvent √† l'aide de mesures telles que l'accuracy, la pr√©cision, le rappel et le score F1. Ces mesures comparent les r√©sultats du mod√®le √† une r√©f√©rence ou √† un √©talon-or.

√âvaluation extrins√®que¬†: √©value les performances du mod√®le dans des applications concr√®tes, en prenant en compte des facteurs tels que la convivialit√©, l'impact et la satisfaction des utilisateurs. Ce type d'√©valuation est plus sp√©cifique √† la t√¢che et peut √™tre subjectif.
</div>

-vertical-

**N√©cessit√© d'indicateurs d'√©valuation**

Nous avons besoin de mesures d'√©valuation pour fournir des mesures quantifiables permettant d'√©valuer la performance des diff√©rents mod√®les.
Sans ces indicateurs, il serait difficile de d√©terminer quel mod√®le est le plus performant. Ces indicateurs d'√©valuation permettent aux chercheurs et aux praticiens en PNL d'identifier les forces et les faiblesses de leurs mod√®les.
Ces indicateurs servent de r√©f√©rence pour de futurs progr√®s et permettent d'affiner continuellement le mod√®le.

-vertical-

**Taux d'erreurs de mots (WER)**

Le taux d'erreurs de mots (WER) √©value les syst√®mes de reconnaissance vocale afin de d√©terminer dans quelle mesure le r√©sultat d'un mod√®le de conversion parole-texte correspond √† la transcription r√©elle du contenu parl√©. Il est calcul√© √† l'aide des √©l√©ments suivants¬†:

$WER = \frac{S+D+I}{N}$

-vertical-

O√π¬†:

S = Substitutions (mots incorrects)

D = Suppressions (mots manquants)

I = Insertions (mots suppl√©mentaires)

N = Nombre total de mots dans la transcription de r√©f√©rence.

En termes plus simples, le WER donne le ratio du nombre d'erreurs (substitutions, suppressions, insertions) par rapport au nombre total de mots dans la transcription de r√©f√©rence.

-vertical-

**Taux de reconnaissance des caract√®res (TRC)**

Le TRC √©value les syst√®mes de reconnaissance optique de caract√®res (OCR). Ces syst√®mes convertissent les images de textes dactylographi√©s ou manuscrits en texte compr√©hensible par ordinateur. Le TRC √©value le pourcentage de caract√®res correctement reconnus par le syst√®me OCR.

Le TRC est calcul√© comme suit¬†:

<div class="r-fit-text">
$CRT = \frac{Number\ of\ correct\ characters}{Total\ number\ of\ characters}*100$
</div>

-vertical-

**Similarit√© s√©mantique textuelle (STS)**

<div class="r-fit-text">
La similarit√© s√©mantique textuelle (STS) est une mesure diff√©rente de celle d√©crite ci-dessus, qui calcule la similarit√© entre deux textes. Cette mesure est particuli√®rement utile dans des applications telles que la traduction automatique, la synth√®se de texte et la recherche d'informations. La STS est calcul√©e √† l'aide de la similarit√© cosinus et de mod√®les pr√©-entra√Æn√©s comme BERT.
</div>

-vertical-

**Entropie crois√©e**

On a vu la derni√®re fois qu'on pouvait calculer l'entropie √† partir d'une distribution. On ne peut donc pas calculer l'entropie d'une langue si on consid√®re qu'elle a un nombre infini d'√©nonc√© possible. A partir du moment o√π l'on consid√®re que l'on peut produire des √©nonc√©s en dehors de ceux d√©j√† observ√©s, on a plus de distribution et on ne peut de ce fait plus calculer l'entropie.

-vertical-

Un mod√®le de langage vise √† apprendre, √† partir d'un texte √©chantillon, une distribution proche de la distribution empirique de la langue. Afin de mesurer la proximit√© de deux distributions, l'entropie crois√©e est souvent utilis√©e. Math√©matiquement, l'entropie crois√©e de Q par rapport √† P est d√©finie comme suit¬†:

<div class="r-fit-text">
$H(P,Q)=-\sum{P(x)log(Q(x))}=-\sum{P(x)log(P(x))-\sum{P(x)log\frac{Q(x)}{P(x)}}}$
</div>

-vertical-

Par cons√©quent, l'entropie crois√©e de Q par rapport √† P est la somme des deux valeurs suivantes¬†:

- le nombre moyen de bits n√©cessaires pour coder tout r√©sultat possible de P √† l'aide du code optimis√© pour P [soit
- entropie de P].
- le nombre de bits suppl√©mentaires n√©cessaires pour coder tout r√©sultat possible de P √† l'aide du code optimis√© pour Q.

-vertical-

Il convient de noter que, puisque l'entropie empirique n'est pas optimisable, lorsque nous formons un mod√®le de langage dans le but de minimiser la perte d'entropie crois√©e, le v√©ritable objectif est de minimiser la divergence KL de la distribution, qui a √©t√© apprise par notre mod√®le de langage √† partir de la distribution empirique du langage.

-vertical-

L'entropie crois√©e √©value la variance entre deux ensembles de probabilit√©s, en juxtaposant souvent des mod√®les de donn√©es r√©elles aux r√©sultats pr√©vus par un mod√®le. Plus l'entropie crois√©e est faible, plus les pr√©dictions du mod√®le s'alignent sur les valeurs r√©elles.

-vertical-

**Perplexit√©**

Intuitivement, la perplexit√© peut √™tre comprise comme une mesure de l'incertitude. La perplexit√© d'un mod√®le de langage peut √™tre consid√©r√©e comme le niveau de perplexit√© lors de la pr√©diction du symbole suivant. Consid√©rons un mod√®le de langage avec une entropie de trois bits, o√π chaque bit code deux r√©sultats possibles de probabilit√© √©gale. Cela signifie que pour pr√©dire le symbole suivant, ce mod√®le de langage doit choisir parmi $2^3=8$ options possibles. On peut donc affirmer que ce mod√®le de langage a une perplexit√© de 8.

-vertical-

Cela √©quivaut √©galement √† l‚Äôexponentiation de l‚Äôentropie crois√©e entre les donn√©es et les pr√©dictions du mod√®le.

$PPL(P,Q)=2^{H(P,Q)}$

-vertical-

**Bits par caract√®re et bits par mot**

<div class="r-fit-text">
Le nombre de bits par caract√®re (BPC) est une autre mesure souvent utilis√©e pour les mod√®les linguistiques r√©cents. Il mesure pr√©cis√©ment la quantit√© qui lui a donn√© son nom¬†: le nombre moyen de bits n√©cessaires pour encoder un caract√®re. Cela nous am√®ne √† revisiter l'explication de Shannon sur l'entropie d'une langue¬†:

¬´¬†Si la langue est traduite en chiffres binaires (0 ou 1) de la mani√®re la plus efficace, l'entropie est le nombre moyen de chiffres binaires n√©cessaires par lettre de la langue d'origine.¬ª

Selon cette d√©finition, l'entropie est le nombre moyen de BPC. 
</div>

-vertical-

<div class="r-fit-text">
La raison pour laquelle certains mod√®les linguistiques rapportent √† la fois la perte d'entropie crois√©e et le BPC est purement technique.

Alors que l'entropie et l'entropie crois√©e sont d√©finies en base logarithmique 2 (avec le bit comme unit√©), les frameworks d'apprentissage automatique populaires, comme TensorFlow et PyTorch, impl√©mentent la perte d'entropie crois√©e en utilisant le logarithme naturel (l'unit√© est alors nat). Cela s'explique par le fait qu'il est plus rapide de calculer le logarithme naturel qu'en base logarithmique 2. En th√©orie, la base logarithmique n'a pas d'importance, car la diff√©rence est une √©chelle fixe¬†:

$\frac{log_en}{log_2n}=\frac{log_e2}{log_ee}=ln2$
</div>

-vertical-

<video src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif" data-autoplay></video>


-vertical-

**Compression**

<div class="r-fit-text">
Hors du contexte de la mod√©lisation du langage, le BPC √©tablit la limite inf√©rieure de la compression. Si un texte a un BPC de 1,2, il ne peut pas √™tre compress√© √† moins de 1,2 bits par caract√®re. Par exemple, si le texte comporte 1¬†000 caract√®res (environ 1¬†000 octets si chaque caract√®re est repr√©sent√© sur 1 octet), sa version compress√©e n√©cessiterait au moins 1¬†200 bits, soit 150 octets.

Inversement, avec un algorithme de compression optimal, nous pourrions calculer l'entropie de la langue anglaise √©crite en compressant l'ensemble du texte anglais disponible et mesurer le nombre de bits des donn√©es compress√©es.
</div>

-vertical-

**Perplexit√© des mod√®les √† longueur fixe**

<div class="r-fit-text">
La perplexit√© (PPL) est l'une des mesures les plus courantes pour √©valuer les mod√®les de langage. Avant d'entrer dans le vif du sujet, il convient de noter que cette mesure s'applique sp√©cifiquement aux mod√®les de langage classiques (parfois appel√©s mod√®les de langage autor√©gressifs ou causaux) et n'est pas bien d√©finie pour les mod√®les de langage masqu√©s comme BERT.

La perplexit√© est d√©finie comme la moyenne exponentielle du logarithme n√©gatif de vraisemblance d'une s√©quence. Si nous avons une s√©quence tokenis√©e $X=(x_0, x_1, x_2, ...)$, alors la perplexit√© de X est √©gale √† :

$PPL(X)=\exp(-\frac{1}{T}\sum{i}{t}{\log{p_\theta(x_i|x_{\<i})}})$
</div>

-vertical-

**Perte logarithmique/log loss/ negative log-likelihood**

La perte logarithmique et l'entropie crois√©e sont identiques.
Pour les probl√®mes de classification, ¬´¬†perte logarithmique¬†¬ª, ¬´¬†entropie crois√©e¬†¬ª et ¬´¬†log-vraisemblance n√©gative¬†¬ª sont utilis√©s de mani√®re interchangeable.

Plus g√©n√©ralement, les termes ¬´¬†entropie crois√©e¬†¬ª et ¬´¬†log-vraisemblance n√©gative¬†¬ª sont utilis√©s de mani√®re interchangeable dans le contexte des fonctions de perte des mod√®les de classification.

-vertical-

La log-vraisemblance n√©gative pour la r√©gression logistique est donn√©e par [‚Ä¶]. On l'appelle aussi fonction d'erreur d'entropie crois√©e.

Par cons√©quent, le calcul de la perte logarithmique donne la m√™me quantit√© que le calcul de l'entropie crois√©e pour la distribution de probabilit√© de Bernoulli. Le calcul de la perte logarithmique moyenne sur le m√™me ensemble de probabilit√©s r√©elles et pr√©dites que dans la section pr√©c√©dente devrait donner le m√™me r√©sultat que le calcul de l'entropie crois√©e moyenne.

-vertical-

**M√©triques sp√©cifiques aux t√¢ches**

Les t√¢ches de ML populaires, comme la traduction automatique et la reconnaissance d'entit√©s nomm√©es, utilisent des m√©triques sp√©cifiques permettant de comparer les mod√®les. Par exemple, diff√©rentes m√©triques ont √©t√© propos√©es pour la g√©n√©ration de texte, allant de BLEU et ses d√©riv√©s tels que GoogleBLEU et GLEU, mais aussi ROUGE, MAUVE, etc.

-vertical-

**M√©triques sp√©cifiques aux jeux de donn√©es**

Certains jeux de donn√©es sont associ√©s √† des m√©triques sp√©cifiques, notamment dans le cas de benchmarks populaires comme GLUE et SQuAD.

<div class="r-fit-text">
> üí° GLUE est en r√©alit√© un ensemble de sous-ensembles diff√©rents pour diff√©rentes t√¢ches. Vous devez donc d'abord choisir celui qui correspond √† la t√¢che NLI, comme mnli, d√©crit comme une ¬´ collection collaborative de paires de phrases avec annotations d'implication textuelle ¬ª.
</div>

Si vous √©valuez votre mod√®le sur un jeu de donn√©es de benchmark comme ceux mentionn√©s ci-dessus, vous pouvez utiliser sa m√©trique d'√©valuation d√©di√©e. Veillez √† respecter le format requis.

-vertical-

## Bonne Pratique

### G√©rer ses environnements de code

-vertical-

Certaines applications ont besoins de version de paquet voire de python diff√©rentes

C'est pourquoi il est crucial de segmenter ses espaces de programmation.

Plusieurs solutions existent:
- les machines virtuelles
- les environnements virtuels
- les containers

-vertical-

**Environnements virtuels**

Permettent de cr√©er des espaces d√©di√©s √† un projet avec des versions diff√©rentes des diff√©rents paquets ou des version de python par exemple.
Les environnements virtuels sont tr√®s l√©ger et tr√®s facile √† mettre en place. Ils utilisent le m√™me espace disque que l'OS. 

-vertical-

Cr√©ation avec virtualenv:

```
apt install pip
pip install virtualenv
virtualenv ENV_NAME
source ./ENV_NAME/bin/activate
```

-vertical-

Cr√©ation avec conda

```
apt install conda
conda create --name ENV_NAME -y python=VERSION
conda activate ENV_NAME
```

Le process pour cr√©er un environnement virtuel avec mambaest le m√™me qu‚Äôavec conda

Il faut parfois initialiser conda avec la commande conda init SHELL_NAME pour faire fonctionner l‚Äôenvironnement

-vertical-

Cr√©ation avec uv

```
uv init project-name
cd project-name
```

-vertical-

Il faut retenir les versions d'installation dans un fichier `requierements.txt`

C'est ce fichier qui permet de travailler √† plusieurs sur un m√™me projet.

-vertical-

**Les containers**

Install docker

```
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

run docker 

```
sudo docker run hello-world
```

-vertical-

Pourquoi les containers sont des outils int√©ressants ?

Contrairement aux machines virtuelles, les containers utilisent des partitions partag√©es avec le syst√®me d'OS. Pourtant, comme les machines virtuelles elles sont bas√©es sur des OS √† part enti√®re. Ca permet au container d'√™tre plus l√©ger qu'une machine virtuelle tout en permettant une compatibilit√© cross-plateform equivalente.

<img src="https://docs.docker.com/get-started/images/docker-architecture.webp" class="r-stretch"/>

-vertical-

Un container fonctionne gr√¢ce √† un `dockerfile` qui determine ses specifications

```
# syntax=docker/dockerfile:1

FROM node:lts-alpine
WORKDIR /app
COPY . .
RUN yarn install --production
CMD ["node", "src/index.js"]
EXPOSE 3000
```


-vertical-

Quizz 2

-vertical-

Quizz 2

3. Expliquez le lien entre Perplexit√©, cross-entropie et logloss/log likelihood.
4. Donnez un exemple de m√©trique intrins√©que et un exemple de m√©trique extrins√®que pour le TAL.
5. Expliquez la diff√©rence entre environnement virtuels et containers.

-vertical-

TP6 :

- Evaluer votre mod√®le avec les m√©triques extrins√®ques adapt√©es √† votre t√¢che.
