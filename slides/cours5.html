---
layout: presentation
title: Cours5
---
# Outils de Traitement de Corpus
cours 5
-vertical-

# Rappel du cours prÃ©cÃ©dent

<h2 class="r-fit-text">ğŸ”„Structurer les donnÃ©es - part 2ğŸ”„</h2>
<h2 class="r-fit-text">ğŸ²Statistiques de corpusğŸ²</h2>
<h2 class="r-fit-text">ğŸ‘“Visualiser les donnÃ©esğŸ‘“</h2>

-vertical-

# Cours 5

<h2 class="r-fit-text">Selectionner des caractÃ©ristiques</h2>
<h2 class="r-fit-text">ğŸ§¼Nettoyer son corpusğŸ§¼</h2>
<h2 class="r-fit-text">ğŸ“MÃ©triques d'Ã©valuationğŸ“</h2>
<h2 class="r-fit-text">ğŸ”¼SignificativitÃ© des rÃ©sultatsâ«</h2>

-horizontal-

<h2 class="r-fit-text">Selectionner des caractÃ©ristiques</h2>

Pour choisir les bonnes caractÃ©ristiques Ã  mettre en relation pour observer nos donnÃ©es, on peut utiliser la corrÃ©lation.

<img src="https://www.simplypsychology.org/wp-content/uploads/correlation.jpg">

-vertical-

Est ce que la temperature est correlÃ©e Ã  la couverture nuageuse?

&rarr; pour le dÃ©terminer on va reprÃ©senter les deux variables dans le mÃªme espace :

<img src="/OutilsTraitementCorpus/slides/img/output_couverturenuageuse_temperature.png">

-vertical-

Ici, il n'est pas clair que les donnÃ©es corrÃ¨llent mais comment le vÃ©rifier ?

&rarr; On va faire des tests de correlation

<p class="fragment">On dÃ©crit les corrÃ©lations Ã  l'aide d'une mesure appelÃ©e coefficient de corrÃ©lation compris entre -1 et +1 et notÃ© r.</p>

-vertical-

Comme on observait prÃ©cÃ©demment, 

<img src="https://www.simplypsychology.org/wp-content/uploads/correlation.jpg">

On peut avoir une corrÃ©lation positive ou une corrÃ©lation nÃ©gative :

- Si la corrÃ©lation est &lt;0, elle est nÃ©gative

&rarr; On peut imaginer que plus la couverture nuageuse est forte, plus la tempÃ©rature baisse

- Si la corrÃ©lation est &gt;0, elle est positive

&rarr; On peut imaginer que plus il fait jour longtemps, plus il fait chaud

-vertical-

Si la corrÃ©lation est proche de 0, on peut imaginer qu'il n'y a pas de corrÃ©lation entre les deux variables.

&rarr; Mais comment dÃ©terminer s'il y a une corrÃ©lation significative ou pas ?

-vertical-

La significativitÃ© statistique est indiquÃ©e par une valeur p ("p-value") comprise entre 0 et 1, du fait qu'il s'agit d'une probabilitÃ©. 
On dÃ©note par alpha la valeur en dessous de laquelle il est admis qu'un rÃ©sultat est significatif.

-vertical-

Dans de nombreux domaines, alpha = 0.05, mais divers seuils peuvent Ãªtre prÃ©sents, pour dÃ©noter significatif (souvent alpha = 0.05), trÃ¨s significatif (souvent alpha = 0.01), extrÃªmement significatif (souvent alpha = 0.001), <i>etc</i>.

<small>Dans des domaines spÃ©cifiques tels que l'astronomie, la significativitÃ© est exprimÃ©e sous la forme d'Ã©cart-types, du fait des distributions gaussiennes, auquel cas un rÃ©sultat est considÃ©rÃ© significatif Ã  partir de 5 Ã©cart-types.</small>

-vertical-

La p-value est impactÃ©e par la quantitÃ© de donnÃ©es : plus on a de donnÃ©es, plus le rÃ©sultat d'ensemble est reprÃ©sentatif de la rÃ©alitÃ© de terrain.

Avec beaucoup de donnÃ©es, il est possible d'avoir des p-values trÃ¨s basses, considÃ©rez dans ce cas l'utilisation de la notation scientifique: 1.5e-10.

-horizontal-

<h2 class="r-fit-text">ğŸ§¼Nettoyer son corpusğŸ§¼</h2>

-vertical-

### DÃ©dupliquer les donnÃ©es

Il faut dÃ©dupliquer les donnÃ©es, pour ne pas biaiser l'apprentissage.

Un systÃ¨me qui apprend va approximer une vÃ©ritÃ© terrain Ã  partir de ses donnÃ©es d'entrainement, qui ne sont qu'un faible Ã©chantillon de la vÃ©ritÃ© de terrain

&rarr; par consÃ©quent, toute surreprÃ©sentation d'un exemple du fait d'une duplication va biaiser le systÃ¨me en lui faisant croire que cet exemple est plus frÃ©quent qu'il ne l'est vraiment.

-vertical-

[https://hplt-project.org/datasets/v1.2](Corpus HPLT)

Comparez la version "raw", la version "deduped"

-vertical-

### Nettoyer les donnÃ©es

On a visualisÃ© nos donnÃ©es avec les mÃ©triques adaptÃ©es Ã  notre tÃ¢che

&rarr; Les mÃ©triques mettent en lien des variables qui sont correlÃ©es

-vertical-

### Rappel

Avec ces observations, on va Ã©galement pouvoir observer si on a des items qui ne correspondent pas Ã  ce que l'on voulait rÃ©cupÃ©rer

>*par exemple :*
Lorsqu'on rÃ©cupÃ¨re des articles de presse, certains sont libres de droits et d'autres sont tronquÃ©s aprÃ¨s quelques lignes d'informations
&rarr; visualiser la taille des textes et des rÃ©sumÃ©s va nous permettre d'Ã©liminer les Ã©lÃ¨ments non pertinents.

-vertical-

### [detecter les donnÃ©es aberrantes](https://fr.khanacademy.org/math/be-4eme-secondaire2/x213a6fc6f6c9e122:statistiques/x213a6fc6f6c9e122:boite-a-moustaches-et-analyse-de-donnees/a/identifying-outliers-iqr-rule) (*outliers*)

Qu'est ce qu'un *outlier* ?

<img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*O3lOgPwuHP7Vfc1T6NDRrQ.png">

-vertical-

Qu'est ce qu'un *outlier* ?

Une valeur aberrante est une valeur qui s'Ã©carte fortement des valeurs des autres observations, anormalement faible ou Ã©levÃ©e.

-vertical-

Il y a deux raison pour avoir ce genre de profil :

- Une erreur de mesure &rarr; Certains Ã©lÃ¨ments de notre corpus ont Ã©tÃ© mal rÃ©cupÃ©rÃ©s
- Une grande variabilitÃ© des donnÃ©es &rarr; les caratÃ©ristiques que l'on observe ne sont pas pertinentes pour juger de la qualitÃ© de nos donnÃ©es

-vertical-

Dans la distribution suivante, combien de valeurs abÃ©rrantes y a-t-il ?

<img src="https://cdn.kastatic.org/ka-perseus-graphie/3e7f4099e3e75172481886495dca4e064732a413.svg">

-vertical-

Une valeur est considÃ©rÃ©e comme aberrante si la valeur absolue de l'Ã©cart avec Q1 ou Q3 est supÃ©rieure Ã  plus de 1,5 x l'Ã©cart interquartile
 
Une valeur aberrante est dite:

- faible si elle est infÃ©rieure Ã  Q1 - 1,5 x l'Ã©cart interquartile
 
- Ã©levÃ©e si elle est supÃ©rieure Ã  Q3 + 1,5 x l'Ã©cart interquartile
 
-vertical-

On peut aussi reprÃ©senter Ã§a sous forme de boÃ®te 

<img src="https://cdn.kastatic.org/ka-perseus-graphie/3e7f4099e3e75172481886495dca4e064732a413.svg">
<img src="https://cdn.kastatic.org/ka-perseus-graphie/09ccd0330dd307840c27ca250e6c0ed7fa7f7b8e.svg">

-vertical-

On veut enlever les donnÃ©es abÃ©rrantes de notre corpus pour conserver les caractÃ©ristiques voulues de notre modÃ¨le

&rarr; Si on veut avoir un modÃ¨le de rÃ©sumÃ© automatique, on veut absolument enlever les paires texte-rÃ©sumÃ© qui ont un ratio de compression trop Ã©levÃ©

-vertical-

âš  Attention toutefois Ã  vÃ©rifier que vous n'enlevez pas trop de donnÃ©es avec cette mÃ©thode et que les donnÃ©es enlevÃ©es sont variÃ©es

&rarr; Dans le cas d'une tÃ¢che de classification, si tous les **outliers** sont des items de la mÃªme classe, il va vous manquer des donnÃ©es pour cette classe.

-vertical-

### Balancer ses donnÃ©es - les problÃ©matiques de classes

Lorsqu'on travaille sur de la classification, on veut avoir un Ã©chantillon reprÃ©sentatif des diffÃ©rentes classes que l'on cherche Ã  prÃ©dire.

Parfois, certaines classes sont plus accessibles que d'autres :

Pour Ã©viter d'obtenir un modÃ¨le qui ne sait prÃ©dire que les classes majoritaires, on va balancer notre dataset.

-vertical-



<!--
-vertical-

Determiner si un objet est aberrant ou pas a Ã  voir avec la notion de distribution statistiques.

Une distribution est une fonction qui associe une frÃ©quence d'apparition Ã  une classe de valeur. Cette fonction permet de rÃ©sumer l'information contenue dans un ensemble de donnÃ©es. (cf. cours de stats de Damien Nouvel)

-vertical-

### Rappel sur les distributions

Lorsqu'on reprÃ©sente nos donnÃ©es, on le fait de maniÃ¨re discrÃ¨te.

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-largeur-classe-histogramme.png">

On represente combien d'objets tombent dans une fenÃªtre de valeur donnÃ©es.

-vertical-

On peut changer la largeur de la fenÃªtre avec le paramÃ¨tre de `bin`

```
import matplotlib.pyplot as plt

plt.hist(height, edgecolor="red", bins=5) 
```

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-impact-augmentation-nombre-classe-graphique.PNG">


-vertical-

Si on pousse notre reprÃ©sentation Ã  l'extrÃªme, On obtient une ligne continue

<img src="https://www.commentprogresser.com/img/statistique/distribution/distributionpoidsgraph.png">

-vertical-
&rarr; c'est la *densitÃ© de probabilitÃ©*

car on peut obtenir la probabilitÃ© d'avoir une valeur contenue dans un intervalle.

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-poids-graph-amplitude.png">
--> 

-vertical-

Comment retirer les donnÃ©es non pertinentes de nos structures de donnÃ©es ?

- pour les `pd.DataFrame`
- pour les `Dataset`
- pour les BDD ?

-vertical-

Avec `pandas` on une mÃ©thode pour dÃ©dupliquer les donnÃ©es:

```DataFrame.drop_duplicates(subset=None, *, keep='first', inplace=False, ignore_index=False)```

Et une mÃ©thode pour supprimer les donnÃ©es suivant les index

```DataFrame.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')```

-vertical-

La bibliothÃ¨que `Datasets` n'a pas de deduplication prÃ© construite

On peut passer par pandas avec `to_pandas`


Ou construire ses propres [fonction de dÃ©duplication](https://github.com/huggingface/transformers/blob/main/examples/research_projects/codeparrot/scripts/preprocessing.py)

-vertical-

Pour les BDD, on a aussi une commande `drop` mais âš  Ce n'est pas pour enlever simplement un point de donnÃ©es !

&rarr; La commande DROP est utilisÃ©e pour supprimer une base de donnÃ©es

Pour supprimer une ligne de donnÃ©es, on va utiliser la commande `delete`

```
DELETE FROM table_name WHERE condition;
```

-horizontal-

<h2 class="r-fit-text">ğŸ“MÃ©triques d'Ã©valuationğŸ“</h2>

-vertical-

Chaque tÃ¢ches disposent de mÃ©triques d'Ã©valuation spÃ©cifiques

-vertical-

ORACLE

-vertical-

LEAD

-horizontal-

â“ Des questions â“

ğŸ’¡ Des idÃ©es ğŸ’¡

<img src="/OutilsTraitementCorpus/slides/img/socrative-qr-code.PNG">

-vertical-


## Le point bonne pratique


**Les conventions de "nommage"** / *naming convention*
la [PEP 8](https://peps.python.org/pep-0008/#naming-conventions)


-vertical-

1. Measure correlation between two features of your dataset
    a. if the correlation is not significant how do you improve the p-value ?

2. Eliminer les donnÃ©es abÃ©rrantes

3. Balancer les classes

    a. En faisant de l'augmentation de donnÃ©es

    b. En faisant de la reduction de donnÃ©es

4. Splitter son corpus en test et train

5. Evaluer son corpus avec les mÃ©triques adaptÃ©es