---
layout: presentation
title: Cours5
---
# Outils de Traitement de Corpus
cours 5
-vertical-

# Rappel du cours précédent

<h2 class="r-fit-text">🔄Structurer les données - part 2🔄</h2>
<h2 class="r-fit-text">🎲Statistiques de corpus🎲</h2>
<h2 class="r-fit-text">👓Visualiser les données👓</h2>

-vertical-

# Cours 5

<h2 class="r-fit-text">Selectionner des caractéristiques</h2>
<h2 class="r-fit-text">🧼Nettoyer son corpus🧼</h2>
<h2 class="r-fit-text">📏Métriques d'évaluation📏</h2>
<h2 class="r-fit-text">🔼Significativité des résultats⏫</h2>

-horizontal-

<h2 class="r-fit-text">Selectionner des caractéristiques</h2>

Pour choisir les bonnes caractéristiques à mettre en relation pour observer nos données, on peut utiliser la corrélation.

<img src="https://www.simplypsychology.org/wp-content/uploads/correlation.jpg">

-vertical-

Est ce que la temperature est correlée à la couverture nuageuse?

&rarr; pour le déterminer on va représenter les deux variables dans le même espace :

<img src="/OutilsTraitementCorpus/slides/img/output_couverturenuageuse_temperature.png">

-vertical-

Ici, il ne semble pas que les données corrèllent mais comment le vérifier ?

&rarr; On va faire des tests de correlation

<p class="fragment">On décrit les corrélations à l'aide d'une mesure appelée coefficient de corrélation compris entre -1 et +1 et noté r.</p>

-vertical-

Comme on observait précédemment, 

<img src="https://www.simplypsychology.org/wp-content/uploads/correlation.jpg">

On peut avoir une corrélation positive ou une corrélation négative :

- Si la corrélation est &lt;0, elle est négative

&rarr; On peut imaginer que plus la couverture nuageuse est forte, plus la température baisse

- Si la corrélation est &gt;0, elle est positive

&rarr; On peut imaginer que plus il fait jour longtemps, plus il fait chaud

-vertical-

Si la corrélation est proche de 0, on peut imaginer qu'il n'y a pas de corrélation entre les deux variables.

&rarr; Mais comment déterminer s'il y a une corrélation significative ou pas ?

-vertical-

La significativité statistique est indiquée par une valeur p ("p-value") comprise entre 0 et 1, du fait qu'il s'agit d'une probabilité. 
On dénote par alpha la valeur en dessous de laquelle il est admis qu'un résultat est significatif.

-vertical-

Dans de nombreux domaines, alpha = 0.05, mais divers seuils peuvent être présents, pour dénoter significatif (souvent alpha = 0.05), très significatif (souvent alpha = 0.01), extrêmement significatif (souvent alpha = 0.001), <i>etc</i>.
<small>Dans des domaines spécifiques tels que l'astronomie, la significativité est exprimée sous la forme d'écart-types, du fait des distributions gaussiennes, auquel cas un résultat est considéré significatif à partir de 5 écart-types.</small>

-vertical-

La p-value est impactée par la quantité de données : plus on a de données, plus le résultat d'ensemble est représentatif de la réalité de terrain.
Avec beaucoup de données, il est possible d'avoir des p-values très basses, considérez dans ce cas l'utilisation de la notation scientifique: 1.5e-10.

-horizontal-

<h2 class="r-fit-text">🧼Nettoyer son corpus🧼</h2>

-vertical-

Il faut dédupliquer les données, pour ne pas biaiser l'apprentissage.
<!-- Dans un apprentissage, un modèle va optimiser un gradient, mais celui-ci est influencé à tort plusieurs fois s'il -->
<!--Si l'on ne déduplique pas, un exemple va avoir une influence démesurée.-->
<!--Un système qui apprend va approximer ses données d'entrainement comme étant la véritable distribution, or, les duplications biaisent la vérité terrain.-->
Un système qui apprend va approximer une vérité terrain à partir de ses données d'entrainement, qui ne sont qu'un faible échantillon de la vérité de terrain ; par conséquent, toute surreprésentation d'un exemple du fait d'une duplication va biaiser le système en lui faisant croire que cet exemple est plus fréquent qu'il ne l'est vraiment.

-vertical-

[https://hplt-project.org/datasets/v1.2](Corpus HPLT)

Comparez la version "raw", la version "deduped", et la version "cleaned" concernant leurs tailles.


-vertical-

On a visualisé nos données avec les métriques adaptées à notre tâche

-vertical-

### Rappel

Avec ces observations, on va également pouvoir observer si on a des items qui ne correspondent pas à ce que l'on voulait récupérer

>*par exemple :*
Lorsqu'on récupère des articles de presse, certains sont libres de droits et d'autres sont tronqués après quelques lignes d'informations
&rarr; visualiser la taille des textes et des résumés va nous permettre d'éliminer les élèments non pertinents.

-vertical-

### [detecter les données aberrantes](https://fr.khanacademy.org/math/be-4eme-secondaire2/x213a6fc6f6c9e122:statistiques/x213a6fc6f6c9e122:boite-a-moustaches-et-analyse-de-donnees/a/identifying-outliers-iqr-rule) (*outliers*)

Qu'est ce qu'un *outlier* ?

<img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*O3lOgPwuHP7Vfc1T6NDRrQ.png">

-vertical-

Qu'est ce qu'un *outlier* ?

Une valeur aberrante est une valeur qui s'écarte fortement des valeurs des autres observations, anormalement faible ou élevée.

-vertical-

Il y a deux raison pour avoir ce genre de profil :

- Une erreur de mesure &rarr; Certains élèments de notre corpus ont été mal récupérés
- Une grande variabilité des données &rarr; les caratéristiques que l'on observe ne sont pas pertinentes pour juger de la qualité de nos données

-vertical-

Dans la distribution suivante, combien de valeurs abérrantes y a-t-il ?

<img src="https://cdn.kastatic.org/ka-perseus-graphie/3e7f4099e3e75172481886495dca4e064732a413.svg">

-vertical-

Une valeur est considérée comme aberrante si la valeur absolue de l'écart avec Q1 ou Q3 est supérieure à plus de 1,5 x l'écart interquartile
 
Une valeur aberrante est dite:

- faible si elle est inférieure à Q1 - 1,5 x l'écart interquartile
 
- élevée si elle est supérieure à Q3 + 1,5 x l'écart interquartile
 
-vertical-

On peut aussi représenter ça sous forme de boîte 

<img src="https://cdn.kastatic.org/ka-perseus-graphie/3e7f4099e3e75172481886495dca4e064732a413.svg">
<img src="https://cdn.kastatic.org/ka-perseus-graphie/09ccd0330dd307840c27ca250e6c0ed7fa7f7b8e.svg">

<!--
-vertical-

Determiner si un objet est aberrant ou pas a à voir avec la notion de distribution statistiques.

Une distribution est une fonction qui associe une fréquence d'apparition à une classe de valeur. Cette fonction permet de résumer l'information contenue dans un ensemble de données. (cf. cours de stats de Damien Nouvel)

-vertical-

### Rappel sur les distributions

Lorsqu'on représente nos données, on le fait de manière discrète.

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-largeur-classe-histogramme.png">

On represente combien d'objets tombent dans une fenêtre de valeur données.

-vertical-

On peut changer la largeur de la fenêtre avec le paramètre de `bin`

```
import matplotlib.pyplot as plt

plt.hist(height, edgecolor="red", bins=5) 
```

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-impact-augmentation-nombre-classe-graphique.PNG">


-vertical-

Si on pousse notre représentation à l'extrême, On obtient une ligne continue

<img src="https://www.commentprogresser.com/img/statistique/distribution/distributionpoidsgraph.png">

-vertical-
&rarr; c'est la *densité de probabilité*

car on peut obtenir la probabilité d'avoir une valeur contenue dans un intervalle.

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-poids-graph-amplitude.png">
--> 

-vertical-


Comment retirer les données non pertinentes de nos structures de données ?

- pour les `pd.DataFrame`
- pour les `Dataset`
- pour les BDD ?

-vertical-

pandas drop

-vertical-

dataset drop

-vertical-

table DROP ? no

-horizontal-

<h2 class="r-fit-text">🔼Significativité des résultats⏫</h2>

-vertical-

p value

test de significativité

-horizontal-

<h2 class="r-fit-text">📏Métriques d'évaluation📏</h2>

-vertical-

ORACLE

-vertical-

LEAD

-horizontal-

❓ Des questions ❓

💡 Des idées 💡

<img src="/OutilsTraitementCorpus/slides/img/socrative-qr-code.PNG">

-vertical-


## Le point bonne pratique


**Les conventions de "nommage"** / *naming convention*
la [PEP 8](https://peps.python.org/pep-0008/#naming-conventions)


-vertical-

1. Measure correlation between two features of your dataset
    a. if the correlation is not significant how do you improve the p-value ?

2. Eliminer les données abérrantes

3. Balancer les classes

    a. En faisant de l'augmentation de données

    b. En faisant de la reduction de données

4. Splitter son corpus en test et train

5. Evaluer son corpus avec les métriques adaptées