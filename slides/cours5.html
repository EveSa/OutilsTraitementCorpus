---
layout: presentation
title: Cours5
---
# Outils de Traitement de Corpus
cours 5
-vertical-

# Rappel du cours pr√©c√©dent

<h2 class="r-fit-text">üîÑStructurer les donn√©es - part 2üîÑ</h2>
<h2 class="r-fit-text">üé≤Statistiques de corpusüé≤</h2>
<h2 class="r-fit-text">üëìVisualiser les donn√©esüëì</h2>

-vertical-

# Cours 5

<h2 class="r-fit-text">Selectionner des caract√©ristiques</h2>
<h2 class="r-fit-text">üîºSignificativit√© des r√©sultats‚è´</h2>
<h2 class="r-fit-text">üßºNettoyer son corpusüßº</h2>
<h2 class="r-fit-text">üìèM√©triques d'√©valuationüìè</h2>

-horizontal-

<h2 class="r-fit-text">Selectionner des caract√©ristiques</h2>

Pour choisir les bonnes caract√©ristiques √† mettre en relation pour observer nos donn√©es, on peut utiliser la corr√©lation.

<img class="r-stretch" src="https://www.simplypsychology.org/wp-content/uploads/correlation.jpg">

-vertical-

Est ce que la temperature est correl√©e √† la couverture nuageuse?

&rarr; pour le d√©terminer on va repr√©senter les deux variables dans le m√™me espace :

<img class="r-stretch" src="/OutilsTraitementCorpus/slides/img/output_couverturenuageuse_temperature.png">

-vertical-

Ici, il n'est pas clair que les donn√©es corr√®llent mais comment le v√©rifier ?

&rarr; On va faire des tests de correlation

<p class="fragment">On d√©crit les corr√©lations √† l'aide d'une mesure appel√©e coefficient de corr√©lation compris entre -1 et +1 et not√© r.</p>

-vertical-

Comme on observait pr√©c√©demment, 

<img src="https://www.simplypsychology.org/wp-content/uploads/correlation.jpg">

<p class="r-fit-text">On peut avoir une corr√©lation positive ou une corr√©lation n√©gative :</p>

-vertical-

- Si la corr√©lation est &lt;0, elle est n√©gative

&rarr; On peut imaginer que plus la couverture nuageuse est forte, plus la temp√©rature baisse

- Si la corr√©lation est &gt;0, elle est positive

&rarr; On peut imaginer que plus il fait jour longtemps, plus il fait chaud

-vertical-

Si la corr√©lation est proche de 0, on peut imaginer qu'il n'y a pas de corr√©lation entre les deux variables.

&rarr; Mais comment d√©terminer s'il y a une corr√©lation significative ou pas ?

-vertical-

La significativit√© statistique est indiqu√©e par une valeur p ("p-value") comprise entre 0 et 1, du fait qu'il s'agit d'une probabilit√©. 
On d√©note par alpha la valeur en dessous de laquelle il est admis qu'un r√©sultat est significatif.

-vertical-

Dans de nombreux domaines, alpha = 0.05, mais divers seuils peuvent √™tre pr√©sents :
- pour d√©noter significatif (souvent alpha = 0.05)
- tr√®s significatif (souvent alpha = 0.01)
- extr√™mement significatif (souvent alpha = 0.001), <i>etc</i>.

<small>Dans des domaines sp√©cifiques tels que l'astronomie, la significativit√© est exprim√©e sous la forme d'√©cart-types, du fait des distributions gaussiennes, auquel cas un r√©sultat est consid√©r√© significatif √† partir de 5 √©cart-types.</small>

-vertical-

La p-value est impact√©e par la quantit√© de donn√©es : plus on a de donn√©es, plus le r√©sultat d'ensemble est repr√©sentatif de la r√©alit√© de terrain.

Avec beaucoup de donn√©es, il est possible d'avoir des p-values tr√®s basses, consid√©rez dans ce cas l'utilisation de la notation scientifique: 1.5e-10.

-vertical-

### p-value

Dans un pile-ou-face, on souhaite savoir si la pi√®ce est biais√©e.
Moyen: lancer la pi√®ce un grand nombre de fois, et voir si une tendance √©merge.

> Exemple : lancer_la_piece(n=256, p=0.25)

<p class="r-fit-text">R√©sultat : pile, face, pile, face, pile, pile, pile, face, pile, pile</p>

-vertical-

_Probl√®me: m√™me si la pi√®ce n'est pas biais√©e, la s√©rie qu'on observe reste possible._

Se pose alors la question : quelle est la probabilit√© d'observer une s√©rie au moins aussi extr√™me que celle observ√©e (dans notre cas, s'√©carter encore plus du 50/50). (cf. les cours de Damien Nouvel)
Cela correspond √† la *p-value*.

-vertical-

[notebook test de significativit√©](/OutilsTraitementCorpus/notebooks/significativity_test.ipynb)

-horizontal-

<h2 class="r-fit-text">üßºNettoyer son corpusüßº</h2>

-vertical-

### D√©dupliquer les donn√©es

Il faut d√©dupliquer les donn√©es, pour ne pas biaiser l'apprentissage.

Un syst√®me qui apprend va approximer une v√©rit√© terrain √† partir de ses donn√©es d'entrainement, qui ne sont qu'un faible √©chantillon de la v√©rit√© de terrain

&rarr; par cons√©quent, toute surrepr√©sentation d'un exemple du fait d'une duplication va biaiser le syst√®me en lui faisant croire que cet exemple est plus fr√©quent qu'il ne l'est vraiment.

-vertical-

(https://hplt-project.org/datasets/v1.2)[Corpus HPLT]

Comparez la version "raw" et la version "deduped"

<p class="fragment">22 TB of raw files &rarr; 11 TB of deduped files</p>

-vertical-

### Nettoyer les donn√©es

On a visualis√© nos donn√©es avec les m√©triques adapt√©es √† notre t√¢che

&rarr; Les m√©triques mettent en lien des variables qui sont correl√©es

-vertical-

### Rappel

Avec ces observations, on va √©galement pouvoir observer si on a des items qui ne correspondent pas √† ce que l'on voulait r√©cup√©rer

>*par exemple :*
Lorsqu'on r√©cup√®re des articles de presse, certains sont libres de droits et d'autres sont tronqu√©s apr√®s quelques lignes d'informations
&rarr; visualiser la taille des textes et des r√©sum√©s va nous permettre d'√©liminer les √©l√®ments non pertinents.

-vertical-

### [detecter les donn√©es aberrantes](https://fr.khanacademy.org/math/be-4eme-secondaire2/x213a6fc6f6c9e122:statistiques/x213a6fc6f6c9e122:boite-a-moustaches-et-analyse-de-donnees/a/identifying-outliers-iqr-rule) (*outliers*)

Qu'est ce qu'un *outlier* ?

<img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*O3lOgPwuHP7Vfc1T6NDRrQ.png">

-vertical-

Qu'est ce qu'un *outlier* ?

Une valeur aberrante est une valeur qui s'√©carte fortement des valeurs des autres observations, anormalement faible ou √©lev√©e.

-vertical-

Il y a deux raison pour avoir ce genre de profil :

- Une erreur de mesure &rarr; Certains √©l√®ments de notre corpus ont √©t√© mal r√©cup√©r√©s
- Une grande variabilit√© des donn√©es &rarr; les carat√©ristiques que l'on observe ne sont pas pertinentes pour juger de la qualit√© de nos donn√©es

-vertical-

Dans la distribution suivante, combien de valeurs ab√©rrantes y a-t-il ?

<img src="https://cdn.kastatic.org/ka-perseus-graphie/3e7f4099e3e75172481886495dca4e064732a413.svg">

-vertical-

Une valeur est consid√©r√©e comme aberrante si la valeur absolue de l'√©cart avec Q1 ou Q3 est sup√©rieure √† plus de 1,5 x l'√©cart interquartile
 
Une valeur aberrante est dite:

- faible si elle est inf√©rieure √† Q1 - 1,5 x l'√©cart interquartile
 
- √©lev√©e si elle est sup√©rieure √† Q3 + 1,5 x l'√©cart interquartile
 
-vertical-

On peut aussi repr√©senter √ßa sous forme de bo√Æte 

<div class="r-fit-text">
<img src="https://cdn.kastatic.org/ka-perseus-graphie/3e7f4099e3e75172481886495dca4e064732a413.svg">
</div>
<div class="r-fit-text">
<img class="r-fit-text" src="https://cdn.kastatic.org/ka-perseus-graphie/09ccd0330dd307840c27ca250e6c0ed7fa7f7b8e.svg">
</div>

-vertical-

On veut enlever les donn√©es ab√©rrantes de notre corpus pour conserver les caract√©ristiques voulues de notre mod√®le

&rarr; Si on veut avoir un mod√®le de r√©sum√© automatique, on veut absolument enlever les paires texte-r√©sum√© qui ont un ratio de compression trop √©lev√©

-vertical-

‚ö† Attention toutefois √† v√©rifier que vous n'enlevez pas trop de donn√©es avec cette m√©thode et que les donn√©es enlev√©es sont vari√©es

&rarr; Dans le cas d'une t√¢che de classification, si tous les **outliers** sont des items de la m√™me classe, il va vous manquer des donn√©es pour cette classe.

-vertical-

On peut √©galement couper la distribution pour √©viter les valeurs trop √©loign√©es

<img class="r-stretch" src="https://media.nngroup.com/media/editor/2021/11/29/ecommerce-long-tails.jpg">

-vertical-

(https://hplt-project.org/datasets/v1.2)[Corpus HPLT]

Comparez la version "deduped" et la version "cleaned"

<p class="fragment">11 TB of deduped files &rarr; 8.6 TB of cleaned files</p>

-vertical-

Comment retirer les donn√©es non pertinentes de nos structures de donn√©es ?

- pour les `pd.DataFrame`
- pour les `Dataset`
- pour les BDD ?

-vertical-

Avec `pandas` on une m√©thode pour d√©dupliquer les donn√©es:

```DataFrame.drop_duplicates(subset=None, *, keep='first', inplace=False, ignore_index=False)```

Et une m√©thode pour supprimer les donn√©es suivant les index

```DataFrame.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')```

-vertical-

La biblioth√®que `Datasets` n'a pas de deduplication pr√© construite

On peut passer par pandas avec `to_pandas`


Ou construire ses propres [fonction de d√©duplication](https://github.com/huggingface/transformers/blob/main/examples/research_projects/codeparrot/scripts/preprocessing.py)

-vertical-

Pour les BDD, on a aussi une commande `drop` mais ‚ö† Ce n'est pas pour enlever simplement un point de donn√©es !

&rarr; La commande DROP est utilis√©e pour supprimer une base de donn√©es

Pour supprimer une ligne de donn√©es, on va utiliser la commande `delete`

```
DELETE FROM table_name WHERE condition;
```
-vertical-

### Balancer ses donn√©es - les probl√©matiques de classes

Lorsqu'on travaille sur de la classification, on veut avoir un √©chantillon repr√©sentatif des diff√©rentes classes que l'on cherche √† pr√©dire.

Parfois, certaines classes sont plus accessibles que d'autres :

Pour √©viter d'obtenir un mod√®le qui ne sait pr√©dire que les classes majoritaires, on va balancer notre dataset.

-vertical-

Pour Un probl√®me de classification, on a deux m√©thodes :

- la r√©duction de donn√©es

- l'augmentation de donn√©es

-vertical-

### La r√©duction de donn√©es

Pour balancer un corpus avec r√©duction de donn√©es, c'est facile :

On va diminuer la pr√©gnance des classes majoritaires pour avoir le m√™me nombres d'exemple pour chaques classes.

-vertical-

Pour le down sampling, on peut utiliser la biblioth√®que `scikit learn`

```
sklearn.utils.resample(*arrays, replace=True, n_samples=None, random_state=None, stratify=None)
```

O√π on donnera `n_samples` le nombre d'√©l√©ments dans la plus petite classe

-vertical-

### L'augmentation de donn√©es

L'augmentation de donn√©es peut √™tre utilis√© plus largement que seulement pour la classification. Pour le machine learning, on peut rester sur des m√©thodes de over-sampling.

```
from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=0)
X_resampled, y_resampled = ros.fit_resample(X, y)
```

-vertical-

### L'augmentation de donn√©es

La pr√©cision et l‚Äôefficacit√© du Deep Learning d√©pendent largement de la qualit√© et de la quantit√© des donn√©es d'apprentissage. Et m√™me si nous sommes pleinement dans l‚Äô√®re du Big data , la quantit√© d‚Äôinformation disponible est parfois insuffisante dans la construction de mod√®le d'apprentissage profond. C‚Äôest √† cet instant qu‚Äôintervient la data augmentation.

-vertical-

- Les donn√©es synth√©tiques : ce sont les donn√©es g√©n√©r√©es artificiellement sans r√©f√©rence du monde r√©el par des mod√®les g√©n√©ratifs.
- Les donn√©es augment√©es : ce sont des donn√©es originales, auxquelles ont √©t√© ajout√©es des transformations mineures (comme la traduction de donn√©es textuelles dans une autre langue, la rotation d‚Äôune image ou l‚Äôajout de bruit sur une vid√©o). Ces transformations permettent ainsi d‚Äôaugmenter la diversit√© de l‚Äôensemble d‚Äôapprentissages.

-vertical-

Pour les donn√©es textuelles, on recourt souvent aux m√©thodes suivantes:

- le remplacement de synonymes, l‚Äôinsertion, l‚Äô√©change et la suppression de mots. 
- La r√©trotraduction : le texte traduit de la langue cible est retraduit vers sa langue d‚Äôorigine.

-vertical-

HuggingFace (encore) propose une [m√©thode](https://huggingface.co/docs/datasets/en/process#data-augmentation) d'augmentation de donn√©es √† l'aide de mod√®les de langue masqu√© comme RoBERTA.

```
'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .',
 'Amrozi accused his brother, whom he called " the witness ", of deliberately withholding his evidence.',
 'Amrozi accused his brother, whom he called " the witness ", of deliberately suppressing his evidence.',
 'Amrozi accused his brother, whom he called " the witness ", of deliberately destroying his evidence.',
 "Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .",
 'Yucaipa owned Dominick Stores before selling the chain to Safeway in 1998 for $ 2.5 billion.',
 "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $ 2.5 billion.",
 'Yucaipa owned Dominick Pizza before selling the chain to Safeway in 1998 for $ 2.5 billion.'
 ```

-vertical-

‚ö† L'augmentation de donn√©es pr√©sente plusieurs limites

- Les biais inh√©rents aux donn√©es originales persistent dans les donn√©es augment√©es, et peuvent m√™me √™tre renforc√©s. 
- La garantie de la qualit√© des ensembles de donn√©es augment√©s artificiellement a aussi un co√ªt. 
- La cr√©ation de donn√©es synth√©tiques n√©cessite des ressources importantes (comp√©tences, applications avanc√©es, recherche et d√©veloppement‚Ä¶).

-horizontal-

<h2 class="r-fit-text">üìèM√©triques d'√©valuationüìè</h2>

-vertical-

On distingue 3 types de m√©triques diff√©rentes:

- les m√©triques g√©n√©riques (applicables sur un grand nombre de t√¢ches et de corpus)
- les m√©triques adapt√©es √† une t√¢che (applicable pour une t√¢che ou un ensemble de t√¢ches donn√©s)
- les m√©triques de corpus (sp√©cifique √† un corpus benchmark)

-vertical-

### Les m√©triques g√©n√©riques

Pour les t√¢ches de machine learning classique sur des donn√©es supervis√©e, on conna√Æt des m√©triques:

<div class="r-stretch">

<ul>
    <li>la pr√©cision</li>
    <li>le rappel</li>
    <li>la f-mesure</li>
</ul>

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png">
</div>

-vertical-

<div class="r-stretch">

<p>l'accuracy</p>

<img src="https://www.portaspecs.com/wp-content/uploads/2019/09/Image-1.png">

Ou pour de la g√©n√©ration de texte :

- la perplexit√©

</div>

-vertical-

Intuitivement, la perplexit√© peut √™tre comprise comme une mesure de l‚Äôincertitude.

<img src="https://thegradient.pub/content/images/2019/10/lm-1.png">

La perplexit√© d'un mod√®le de langage peut √™tre consid√©r√©e comme le niveau de perplexit√© lors de la pr√©diction du symbole suivant. Consid√©rons un mod√®le de langage avec une entropie de trois bits, dans lequel chaque bit code deux r√©sultats possibles d'√©gale probabilit√©. Cela signifie que lors de la pr√©diction du prochain symbole, ce mod√®le de langage doit choisir parmi 2^3 = 8 options possibles. Ainsi, nous pouvons affirmer que ce mod√®le de langage a une perplexit√© de 8.

-vertical-

### Les m√©triques sp√©cifiques

Des m√©triques sont adapt√©es √† des t√¢ches en particulier comme la traduction automatique ou la d√©tection d'entit√© nomm√©e.

Ces m√©triques sont utilis√©es pour comparer les mod√®les mais peuvent aussi √™tre utilis√©es pour √©valuer les corpus !

&rarr; c'est ce qui va nous int√©resser ici.

-vertical-

Pour donner aux personnes qui vont utiliser votre corpus des rep√®res sur les scores qu'ils doivent obtenir, on donne :

- une limite haute au score qu'il est possible d'obtenir (qu'on appelle souvent ORACLE)
- une limite basse (LEAD pour le r√©sum√© automatique par exemple)

-vertical-

&rarr; Si les mod√®les sont au dessus de l'oracle ou en dessous de la borne inf√©rieure : il y a un probl√®me dans le processus.

&rarr; Pour certains dataset, le meilleur score qu'il est possible d'obtenir n'est pas de 100%. Il est important de sp√©cifier quel est le score maximal pour avoir une bonne id√©e de la qualit√© de notre mod√®le.

-vertical-

### Les m√©triques de corpus

Lorsque votre corpus propose une t√¢che un peu diff√©rente des autres corpus, vous pouvez proposer une m√©trique adapt√©e.

On peut noter par exemple la m√©trique propos√©e par SQuAD ou pour le Benchmark de GLUE

-vertical-

### Rappel : Qu'est ce qu'un benchmark ?

Dans le contexte de l‚ÄôIA, l‚Äôanalyse comparative implique l‚Äô√©valuation syst√©matique des mod√®les et syst√®mes d‚ÄôIA par rapport √† des param√®tres sp√©cifiques. &rarr; sur un corpus donn√©

> exemple de benchmark : MMLU, Winogrande

[HuggingFace Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

-vertical-

### O√π trouver et comment lancer les m√©triques d'√©valuation

Les m√©triques d'√©valuation des corpus sont une probl√©matique sp√©cifique au deep learning. La biblioth√®que qui implemente leur calcul est donc tr√®s performante sur huggingFace.

HuggingFace propose une [librairie pour l'√©valuation des mod√®les](https://huggingface.co/docs/evaluate/index) qui peut √™tre adapt√© pour l'√©valuation des corpus.

-horizontal-

‚ùì Des questions ‚ùì

üí° Des id√©es üí°

<img class="r-stretch" src="/OutilsTraitementCorpus/slides/img/socrative-qr-code.PNG">

-vertical-


## Le point bonne pratique


**Les conventions de "nommage"** / *naming convention*
la [PEP 8](https://peps.python.org/pep-0008/#naming-conventions)


-vertical-

1. Mesurer la correlation entre deux variables de votre corpus (ex. longueur des textes/longueur des r√©sum√©s)
    a. Comment augmenter la p-value si elle n'est pas significative ?

2. Eliminer les donn√©es ab√©rrantes

3. Augmenter ses donn√©es

4. Splitter son corpus en test et train

5. Evaluer son corpus avec les m√©triques adapt√©es

6. Proposer une m√©trique pour son corpus autre que les m√©triques de la t√¢che

-horizontal-

### R√©f√©rences

https://datascientest.com/data-augmentation-tout-savoir

https://www.jmp.com/fr_ca/statistics-knowledge-portal/what-is-correlation.html

https://webusers.i3s.unice.fr/~crescenz/publications/Florence/valeurs-manquantes-ou-aberrantes.pdf

https://huggingface.co/docs/evaluate/choosing_a_metric

https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/


<aside class="comment">
<!--
-vertical-

Determiner si un objet est aberrant ou pas a √† voir avec la notion de distribution statistiques.

Une distribution est une fonction qui associe une fr√©quence d'apparition √† une classe de valeur. Cette fonction permet de r√©sumer l'information contenue dans un ensemble de donn√©es. (cf. cours de stats de Damien Nouvel)

-vertical-

### Rappel sur les distributions

Lorsqu'on repr√©sente nos donn√©es, on le fait de mani√®re discr√®te.

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-largeur-classe-histogramme.png">

On represente combien d'objets tombent dans une fen√™tre de valeur donn√©es.

-vertical-

On peut changer la largeur de la fen√™tre avec le param√®tre de `bin`

```
import matplotlib.pyplot as plt

plt.hist(height, edgecolor="red", bins=5) 
```

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-impact-augmentation-nombre-classe-graphique.PNG">


-vertical-

Si on pousse notre repr√©sentation √† l'extr√™me, On obtient une ligne continue

<img src="https://www.commentprogresser.com/img/statistique/distribution/distributionpoidsgraph.png">

-vertical-
&rarr; c'est la *densit√© de probabilit√©*

car on peut obtenir la probabilit√© d'avoir une valeur contenue dans un intervalle.

<img src="https://www.commentprogresser.com/img/statistique/distribution/distribution-poids-graph-amplitude.png">
--> 
</aside>
