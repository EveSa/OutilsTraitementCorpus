---
title: Cours2
---
# Outils de Traitement de Corpus
cours 2
-vertical-
# Rappel du cours pr√©c√©dent

<h2 class="r-fit-text">Rappels sur les corpus</h2>
<h2 class="r-fit-text">Focus sur les t√¢ches</h2>
<h2 class="r-fit-text">Les types de donn√©es</h2>
<h2 class="r-fit-text">O√π trouver des corpus</h2>

-vertical-

<!--

## Correction du quizz

1. Qu'est ce que la NTP ?

&rarr; NTP = Next Token Prediction. C'est une t√¢che classique du NLP qui est utilis√©e pour entra√Æner les mod√®les de
langues.

2. Donnez un exemple de t√¢che de TAL utilisant l'apprentissage supervis√©.

&rarr; L'apprentissage supervis√© utilise des donn√©es √©tiquett√©es. On y retrouve les t√¢ches de classification ou de
regression comme la classification de texte ou l'analyse de sentiment.

-vertical-

3. Donnez un framework de donn√©es structur√©es.

&rarr; SQL est un framework de donn√©es structur√©es car les donn√©es y sont typ√©es et instanci√©es

4. Donnez un exemple de donn√©es non structur√©es.

&rarr; un texte brut est une donn√©es non structur√©e

5. Quelles sont vos ressources pour rester informer des avanc√©es de l'IA ?

&rarr; Reddit, Linkedin, X, youtube, ...

-->

-vertical-

## Pr√©sentation des nouvelles

<a src="https://evesa.github.io/OutilsTraitementCorpus/newsletter.html">newsletter</a>

-horizontal-

# Cours 2

# Collecter les donn√©es

-vertical-

### Pourquoi collecter des donn√©es ?

- Des donn√©es sp√©cifiques
    - de t√¢ches
    - de domaine
- des donn√©es confidentielles (m√©dicale, nucl√©aire)

-vertical-

## La qualit√© des mod√®les = la qualit√© des donn√©es

Les mod√®les vont apprendre √† *g√©n√©raliser* sur les donn√©es pr√©sente dans le corpus d'entra√Ænement.

Sans donn√©es, les mod√®les neuronaux n'existent pas (contrairement aux mod√®les de r√®gles par exemple).

-vertical-

## Comment r√©cup√©rer des bonnes donn√©es ?

- Eviter les biais :
    - r√©cup√©rer des donn√©es vari√©es
- Eviter les donn√©es manquantes
- R√©cup√©rer suffisemment de donn√©es

-vertical-

## Consid√©rations √©thiques

Des lois existent pour prot√©ger les donn√©es sur le web :
- les licences
- La RGPD

-vertical-

## R√©cup√©rer des donn√©es

### Depuis des bases pr√©existantes
### Depuis une API
### Depuis le web

## Stocker les donn√©es

-vertical-

## Depuis des base pr√©-existantes

On peut utiliser des bases stock√©es sur des serveurs

&rarr; qu'est ce qu'un serveur ?

Pour cela on va devoir requ√™ter les bases avec un Syst√®me de Gestion de base de Donn√©es (SGBD) type SQL, ou Mongo.

-vertical-

### Avec python,

On va pouvoir connecter sa machine a des bases de donn√©es avec `sqlite3` ou `SQLAlchemy`

-vertical-

### Quelle base pour quel usage ?

SQLite est id√©al pour les applications l√©g√®res et le prototypage.

MySQL et PostgreSQL offrent des solutions de bases de donn√©es plus robustes et adapt√©es aux entreprises, avec des
fonctionnalit√©s √©tendues.

Microsoft SQL Server est privil√©gi√© dans les environnements o√π d'autres technologies Microsoft sont fortement utilis√©es.

-vertical-

### Les bases de donn√©es NoSQL

NoSQL, ou ¬´¬†Not Only SQL¬†¬ª, est un syst√®me de gestion de bases de donn√©es (SGBD) con√ßu pour g√©rer d'importants volumes
de donn√©es non structur√©es et semi-structur√©es. Contrairement aux bases de donn√©es relationnelles traditionnelles qui
utilisent des tables et des sch√©mas pr√©d√©finis, les bases de donn√©es NoSQL offrent des mod√®les de donn√©es flexibles et
prennent en charge l'√©volutivit√© horizontale, ce qui les rend id√©ales pour les applications modernes n√©cessitant un
traitement de donn√©es en temps r√©el.

-vertical-

## Pourquoi utiliser NoSQL¬†?

Contrairement aux bases de donn√©es relationnelles, qui utilisent le langage de requ√™te structur√© (SLR), les bases de
donn√©es NoSQL ne disposent pas d'un langage de requ√™te universel. Chaque type de base de donn√©es NoSQL poss√®de
g√©n√©ralement son propre langage de requ√™te. Les bases de donn√©es relationnelles traditionnelles suivent les
principes ACID (atomicit√©, coh√©rence, isolation, durabilit√©),garantissant une coh√©rence forte et des relations
structur√©es entre les donn√©es.

-vertical-

## Pourquoi utiliser NoSQL¬†?

Cependant, avec l'√©volution des applications vers la gestion du Big Data, de l'analyse en temps r√©el et des
environnements distribu√©s, NoSQL s'est impos√© comme une solution offrant¬†:

<ul class="r-fit-text">
    <li>
√âvolutivit√©¬†: possibilit√© d'√©volutivit√© horizontale par l'ajout de n≈ìuds au lieu de mettre √† niveau une seule
machine¬†;
</li>
<li>
Flexibilit√©¬†: prise en charge des donn√©es non structur√©es ou semi-structur√©es sans sch√©ma rigide¬†;
</li>
<li>
Hautes performances¬†: optimis√© pour des op√©rations de lecture/√©criture rapides sur de grands ensembles de donn√©es¬†;
</li>
<li>
Architecture distribu√©e¬†: con√ßue pour une haute disponibilit√© et une tol√©rance aux partitions dans les syst√®mes
distribu√©s.
</li>
</ul>

-vertical-

### Types de bases de donn√©es NoSQL

Les bases de donn√©es NoSQL sont g√©n√©ralement class√©es en quatre cat√©gories principales selon leur mode de stockage et de
r√©cup√©ration des donn√©es.

1. Bases de donn√©es documentaires

Les donn√©es sont stock√©es sous forme de documents pouvant contenir diff√©rents attributs (json, XML).

Exemples¬†: MongoDB, CouchDB, Cloudant

Id√©al pour les syst√®mes de gestion de contenu, les profils utilisateur et les catalogues n√©cessitant des sch√©mas flexibles.

-vertical-

2. Stockage cl√©-valeur

Les donn√©es sont stock√©es sous forme de paires cl√©-valeur, ce qui acc√©l√®re consid√©rablement la r√©cup√©ration. Optimis√© pour la mise en cache et le stockage de sessions.

Exemples¬†: Redis, Memcached, Amazon DynamoDB

Id√©al pour les applications n√©cessitant la gestion des sessions, la mise en cache des donn√©es en temps r√©el et les classements.

-vertical-

3. Stockage par famille de colonnes

Les donn√©es sont stock√©es en colonnes plut√¥t qu'en lignes, ce qui permet des analyses √† grande vitesse et un calcul distribu√©. Efficace pour le traitement de donn√©es volumineuses avec des exigences √©lev√©es en √©criture/lecture.

Exemples¬†: Apache Cassandra, HBase, Google Bigtable

Id√©al pour les donn√©es de s√©ries chronologiques, les applications IoT et l'analyse du Big Data.

-vertical-

4. Bases de donn√©es √† base graphe

Les donn√©es sont stock√©es sous forme de n≈ìuds et d'ar√™tes, ce qui permet une gestion complexe des relations.
Id√©al pour les r√©seaux sociaux, la d√©tection des fraudes et les moteurs de recommandation.

Exemples¬†: Neo4j, Amazon Neptune, ArangoDB

Utile pour les applications n√©cessitant des requ√™tes relationnelles, telles que la d√©tection des fraudes et l'analyse des r√©seaux sociaux.

-vertical-

### Avec python

Le framework le plus utilis√© pour le NoSQL est MongoDB.

Un libairie pour se connecter √† une base mongo existe en python :

c'est `pymongo`

`PyMongo` est la librairie officielle de MongoDB pour python

-vertical-

Les bases de donn√©es NoSQL sont id√©ales pour les donn√©es semi-structur√©es ou non structur√©es et s'adaptent efficacement
aux flux √† grande vitesse. Leur flexibilit√© et leur √©volutivit√© en font la solution id√©ale pour les charges de travail
dynamiques que les pipelines de ML doivent g√©rer.

-vertical-

Les deux types de bases de donn√©es peuvent √™tre utilis√©s pour l'apprentissage automatique, selon le projet (√† grande ou
petite √©chelle). MySQL (base de donn√©es SQL) r√©pond aux besoins des projets √† petite √©chelle en offrant un nombre
suffisant de fonctionnalit√©s. MongoDB (base de donn√©es NoSQL) est pr√©f√©rable pour la production de projets et leur
exploitation √† grande √©chelle.

-vertical-

## Depuis une API

Qu'est ce qu'une API ?

&rarr; API veut dire **Application Programming Interface**

-vertical-

### Qu'est ce qu'une API

<p class="r-fit-text">
Une API est un ensemble de protocoles et de sous-routines de communication utilis√©s par diff√©rents programmes pour
communiquer entre eux. Un programmeur peut utiliser divers outils API pour simplifier son programme. De plus, une API
offre aux programmeurs un moyen efficace de d√©velopper leurs logiciels. Ainsi, une API permet √† deux programmes ou
applications de communiquer entre eux en leur fournissant les outils et fonctions n√©cessaires. Elle re√ßoit la requ√™te de
l'utilisateur et l'envoie au fournisseur de services, puis renvoie le r√©sultat g√©n√©r√© par ce dernier √† l'utilisateur
souhait√©.
</p>

-vertical-

### Comprendre par l'exemple

<p class="r-fit-text">
Pour illustrer le sch√©ma d'une API, prenons un exemple concret. Imaginez un serveur de restaurant qui √©coute votre
commande, se rend chez le chef, prend les plats command√©s et vous les remet.
</p>

<p class="r-fit-text">
exemple¬†: vous recherchez une formation (par exemple, DSA-Self Paced) sur le site web
XYZ. Vous envoyez une requ√™te (recherche de produit) via une API. La base de donn√©es recherche la formation et v√©rifie
sa disponibilit√©. L'API envoie votre requ√™te √† la base de donn√©es (recherche de la formation) et renvoie le r√©sultat
(meilleurs cours DSA).
</p>

<img height=400 src="https://media.geeksforgeeks.org/wp-content/uploads/20230216170349/What-is-an-API.png" />

-vertical-

### Architecture

REST et GraphQL impl√©mentent tous deux plusieurs principes architecturaux d'API communs. Par exemple, voici les
principes qu'ils partagent :

Les deux √©tant apatrides, le serveur n'enregistre pas l'historique des r√©ponses entre les requ√™tes
Les deux utilisent un mod√®le client-serveur, de sorte que les demandes provenant d'un seul client aboutissent √† des
r√©ponses provenant d'un seul serveur
Les deux sont bas√©s sur HTTP, car HTTP est le protocole de communication sous-jacent

-vertical-

### Conception bas√©e sur les ressources

REST et GraphQL con√ßoivent tous deux leur √©change de donn√©es en fonction des ressources. Une ressource fait r√©f√©rence √†
toute donn√©e ou √† tout objet auquel le client peut acc√©der et manipuler via l'API. Chaque ressource poss√®de son propre
identifiant unique (URI) et un ensemble d'op√©rations (m√©thodes HTTP) que le client peut effectuer sur elle.

-vertical-

### Exemple

Prenons l'exemple d'une API de r√©seaux sociaux dans laquelle les utilisateurs cr√©ent et g√®rent des publications. Dans
une API bas√©e sur les ressources, une publication serait une ressource. Elle poss√®de son propre identifiant unique, par
exemple /posts/1234. Et elle dispose d'un ensemble d'op√©rations, telles que GET pour r√©cup√©rer la publication dans REST
ou query pour r√©cup√©rer la publication dans GraphQL.

-vertical-

### Data Exchange

<p class="r-fit-text">
REST et GraphQL prennent tous deux en charge des formats de donn√©es similaires.
</p>

<p class="r-fit-text">
JSON est le format d'√©change de donn√©es le plus populaire que tous les langages, plateformes et syst√®mes comprennent. Le
serveur renvoie des donn√©es JSON au client. D'autres formats de donn√©es sont disponibles mais moins couramment utilis√©s,
notamment XML et HTML.
</p>

<p class="r-fit-text">
De m√™me, REST et GraphQL prennent tous deux en charge la mise en cache. Ainsi, les clients et les serveurs peuvent
mettre en cache les donn√©es fr√©quemment consult√©es pour acc√©l√©rer les communications.
</p>

-vertical-

### Neutralit√© du langage et de la base de donn√©es

Les API GraphQL et REST fonctionnent avec n'importe quelle structure de base de donn√©es et n'importe quel langage de
programmation, √† la fois c√¥t√© client et c√¥t√© serveur. Cela les rend hautement interop√©rables avec n'importe quelle
application.

-vertical-

## Diff√©rences REST/GraphQL

le d√©veloppement de REST s'est davantage concentr√© sur la cr√©ation de nouvelles API. Dans le m√™me temps, GraphQL s'est
concentr√© sur les performances et la flexibilit√© des API.

-vertical-

### Exemple

Voici ce qu'une requ√™te REST utilise pour fonctionner :

- Verbes HTTP qui d√©terminent l'action
- Une URL qui identifie la ressource sur laquelle le verbe HTTP doit √™tre activ√©
- Les param√®tres et valeurs √† analyser si vous souhaitez cr√©er ou modifier un objet au sein d'une ressource c√¥t√© serveur
existante

<p class="r-fit-text">
Par exemple, vous utilisez GET pour obtenir des donn√©es en lecture seule √† partir d'une ressource, POST pour ajouter une
nouvelle entr√©e de ressource ou PUT pour mettre √† jour une ressource.
</p>

-vertical-

### Diff√©rences REST/GraphQL

En revanche, voici ce que les requ√™tes GraphQL utilisent :

- Requ√™te pour obtenir des donn√©es en lecture seule
- Mutation pour modifier les donn√©es
- Abonnement pour recevoir des mises √† jour de donn√©es bas√©es sur des √©v√©nements ou en streaming

-vertical-

### Diff√©rences REST/GraphQL

Dans l'architecture REST, les donn√©es sont renvoy√©es au client par le serveur dans la structure compl√®te des ressources
sp√©cifi√©e par le serveur. Les exemples suivants montrent les donn√©es renvoy√©es dans REST et GraphQL.

-vertical-

Exemple de donn√©es renvoy√©es dans REST
Dans REST, GET /posts renvoie ce qui suit :

```
[
{
¬´ id ¬ª : 1,
¬´ titre ¬ª : ¬´ Premier message ¬ª,
¬´ content ¬ª : ¬´ Ceci est le contenu du premier post. ¬ª
},
{
¬´ id ¬ª : 2,
¬´ titre ¬ª : ¬´ Deuxi√®me message ¬ª,
¬´ contenu ¬ª : ¬´ Ceci est le contenu du deuxi√®me message ¬ª
},
{
¬´ id ¬ª : 3,
¬´ titre ¬ª : ¬´ Troisi√®me message ¬ª,
¬´ contenu ¬ª : ¬´ Ceci est le contenu du troisi√®me message. ¬ª
}
]
```

-vertical-

Exemple de donn√©es renvoy√©es dans GraphQL
Lorsque vous utilisez GraphQL, seules les donn√©es sp√©cifi√©es dans la structure fournie par le client sont renvoy√©es.

GET /graphql?query{post(id: 1) {id title content}} renvoie uniquement le premier message :

```
{
¬´ donn√©es ¬ª : {
"messages": [
{
¬´ id ¬ª : ¬´ 1 ¬ª,
¬´ titre ¬ª : ¬´ Premier message ¬ª,
¬´ content ¬ª : ¬´ Ceci est le contenu du premier post. ¬ª
},
]}}
```

-vertical-

### Quand utiliser GraphQL vs. REST

Vous pouvez utiliser les API GraphQL et REST de mani√®re interchangeable. Cependant, dans certains cas d'utilisation,
l'un ou l'autre convient mieux.

-vertical-

Par exemple, GraphQL est probablement un meilleur choix si vous tenez compte des points suivants :

- Vous avez une bande passante limit√©e et vous souhaitez minimiser le nombre de demandes et de r√©ponses
- Vous disposez de plusieurs sources de donn√©es et vous souhaitez les combiner sur un seul point de terminaison
- Les demandes de vos clients varient consid√©rablement et vous vous attendez √† des r√©ponses tr√®s diff√©rentes

-vertical-

### Quand utiliser GraphQL vs. REST

D'un autre c√¥t√©, REST est probablement un meilleur choix si vous tenez compte des consid√©rations suivantes :

- Vous avez des applications plus petites avec des donn√©es moins complexes
- Vous disposez de donn√©es et d'op√©rations que tous les clients utilisent de la m√™me mani√®re
- Vous n'avez aucune exigence en mati√®re de requ√™tes de donn√©es complexes

-vertical-

### Et avec Python ?

Pour r√©cup√©rer des donn√©es depuis le web (que ce soit API ou d'autres types de donn√©es), on utilise la biblioth√®que
`requests`

La biblioth√®que `Requests` est la norme de facto pour les requ√™tes HTTP en Python. Elle simplifie les requ√™tes gr√¢ce √†
une API simple et √©l√©gante, vous permettant ainsi de vous concentrer sur l'interaction avec les services et la
consommation de donn√©es dans votre application.

-vertical-

### Et avec Python ?

```
>>> import requests
>>> response = requests.get("https://api.github.com")
>>> response.content
```

Sur une API, on obtient un r√©sultat en `json` qui est facile √† parser

-vertical-

### G√©rer les r√©ponses des APIs

Le python ne g√®re pas le format json de mani√®re native.

Le format json se rapproche de la structure en dictionnaire de python

la biblioth√®que `json` permet de traduire des donn√©es json vers un format dictionnaire exploitable en python.

Pour lire des cha√Ænes de caract√®res json, on utilise la m√©thode :

```
json.loads()
```

-vertical-

### G√©rer les r√©ponses des APIs

On peut aussi directement utiliser la biblioth√®que `pandas` pour g√©rer les donn√©es renvoy√©e en json

```
import pandas as pd

pd.from_json()
```

-vertical-

### Limite de d√©bit

Comme pour toutes requ√™tes envoy√©es sur des serveurs, une limite de requ√™te est d√©cid√©e par les architectes des syst√®mes
en fonction des specifications des machines.

les API limitent le nombre de requ√™tes d'API REST que vous pouvez pr√©senter dans un laps de temps donn√©. Cette limite
permet d'√©viter la mauvaise utilisation et les attaques par d√©ni de service, et garantit que l'API reste disponible pour
tous les utilisateurs.

-vertical-

### Les authentifications API

L'authentification API est le processus de v√©rification de l'identit√© d'un utilisateur effectuant une requ√™te API. Il
s'agit d'un pilier essentiel de la s√©curit√© des API. Il existe de nombreux types d'authentification API, tels que
l'authentification HTTP de base, l'authentification par cl√© API, JWT et OAuth, et chacun pr√©sente ses propres avantages,
inconv√©nients et cas d'utilisation id√©aux. N√©anmoins, tous les m√©canismes d'authentification API ont pour objectif
commun de prot√©ger les donn√©es sensibles et de garantir que l'API ne soit pas utilis√©e √† mauvais escient.

-vertical-

### Les m√©thodes d'authentification

<p class="r-fit-text">
L'authentification HTTP de base est la m√©thode la plus rudimentaire pour impl√©menter l'authentification API. Elle
consiste √† envoyer des identifiants sous forme de paires utilisateur/mot de passe dans un champ d'en-t√™te Authorization,
o√π les identifiants sont cod√©s en Base64. Cependant, ces identifiants ne sont ni hach√©s ni chiffr√©s, ce qui rend ce
m√©canisme d'authentification peu s√ªr, sauf s'il est utilis√© conjointement avec HTTPS.
</p>

<img height=400 src="https://voyager.postman.com/illustration/http-basic-auth-diagram-postman.svg" />

-vertical-

### Les m√©thodes d'authentification

<p class="r-fit-text">
Une cl√© API est un identifiant unique qu'un fournisseur d'API attribue aux utilisateurs enregistr√©s afin de contr√¥ler
leur utilisation et de surveiller leur acc√®s. La cl√© API doit √™tre envoy√©e avec chaque requ√™te, soit dans la cha√Æne de
requ√™te, soit comme en-t√™te de requ√™te, soit comme cookie. Comme l'authentification HTTP de base, l'authentification par
cl√© API doit √™tre utilis√©e avec HTTPS pour garantir la s√©curit√© de la cl√© API.
</p>

<img src="https://voyager.postman.com/illustration/api-key-auth-diagram-postman.svg" height=400 />

-vertical-

### Les m√©thodes d'authentification

<p class="r-fit-text">
OAuth est un m√©canisme d'authentification bas√© sur des jetons qui permet √† un utilisateur d'accorder l'acc√®s √† son
compte √† des tiers sans avoir √† partager ses identifiants de connexion. OAuth 2.0, plus flexible et √©volutif qu'OAuth
1.0, est devenu la r√©f√©rence en mati√®re d'authentification API et prend en charge une int√©gration API compl√®te sans
compromettre les donn√©es utilisateur.
</p>

<img src="https://voyager.postman.com/illustration/oauth-diagram-postman.svg" height=400 />

-vertical-

### Quiz 1

1. Quelle est la diff√©rence entre SQL et NoSQL ?

2. Donnez le nom d'un SGBD de NoSQL.

3. Que veut dire API ?

-horizontal-

## Depuis le web

Le *web scraping* est une m√©thode automatique permettant d'extraire de grandes quantit√©s de donn√©es de sites web. La plupart de ces donn√©es sont des donn√©es non structur√©es au format HTML, qui sont ensuite converties en donn√©es structur√©es dans un tableur ou une base de donn√©es afin d'√™tre exploit√©es dans diverses applications. Il existe de nombreuses fa√ßons d'extraire des donn√©es de sites web gr√¢ce au web scraping. 

-vertical-

## Depuis le web

Parmi celles-ci, on peut citer l'utilisation de services en ligne, d'API sp√©cifiques ou m√™me la cr√©ation de code web scraping de A √† Z. De nombreux grands sites web, comme Google, Twitter, Facebook, StackOverflow, etc., disposent d'API permettant d'acc√©der √† leurs donn√©es dans un format structur√©. C'est la meilleure option, mais d'autres sites ne permettent pas d'acc√©der √† de grandes quantit√©s de donn√©es sous une forme structur√©e ou ne sont tout simplement pas assez avanc√©s technologiquement. Dans ce cas, il est pr√©f√©rable d'utiliser le web scraping pour extraire les donn√©es du site web.

-vertical-

### Crawler et Scrapper

Le web scraping se compose de deux √©l√©ments¬†: le robot d'exploration (crawler) et le scraper. Le robot d'exploration est un algorithme qui parcourt le web √† la recherche des donn√©es n√©cessaires en suivant les liens. Le scraper, quant √† lui, est un outil sp√©cifique con√ßu pour extraire les donn√©es du site web. La conception du scraper peut varier consid√©rablement selon la complexit√© et l'ampleur du projet, afin de permettre une extraction rapide et pr√©cise des donn√©es.

-vertical-

### Comment fonctionnent les crawlers ?

Internet est en constante √©volution et expansion. Parce qu'il n'est pas possible de savoir combien de pages web existent au total sur Internet, les robots d'indexation commencent √† partir d'une graine, c'est-√†-dire une liste d'URL connues. Ils exploreront d'abord les pages web de ces URL. En indexant ces pages web, ils trouveront des hyperliens vers d'autres URL et les ajouteront √† la liste des pages √† indexer ensuite.

-vertical-

### Exigences de robots.txt

les robots d'indexation d√©cident √©galement des pages √† explorer en se basant sur le protocole robots.txt (√©galement appel√© protocole d'exclusion des robots). Avant d‚Äôindexer une page web, ils v√©rifient le fichier robots.txt h√©berg√© par le serveur web de cette page. Un fichier robots.txt est un fichier texte qui d√©finit les r√®gles d‚Äôacc√®s √† l‚Äôapplication ou au site Web h√©berg√©. Ces r√®gles d√©finissent les pages que les bots peuvent indexer et les liens qu‚Äôils peuvent suivre. √Ä titre d'exemple, consultez le fichier robots.txt de Cloudflare.com.

-vertical-

### Comment fonctionnent les scrapers web¬†?

Les scrapers web peuvent extraire toutes les donn√©es de sites sp√©cifiques ou les donn√©es sp√©cifiques recherch√©es par un utilisateur. Id√©alement, il est pr√©f√©rable de sp√©cifier les donn√©es souhait√©es afin que le scraper web les extraie rapidement. Par exemple, vous pourriez vouloir scraper une page Amazon pour conna√Ætre les types de centrifugeuses disponibles, mais vous pourriez ne vouloir que les donn√©es concernant les diff√©rents mod√®les, sans les avis clients.

-vertical-

### Comment fonctionnent les scrapers web¬†?

Ainsi, lorsqu'un scraper web doit scraper un site, il commence par fournir les URL. Il charge ensuite tout le code HTML de ces sites. Un scraper plus avanc√© peut m√™me extraire tous les √©l√©ments CSS et JavaScript. Le scraper r√©cup√®re ensuite les donn√©es requises √† partir de ce code HTML et les affiche au format sp√©cifi√© par l'utilisateur. Il s'agit g√©n√©ralement d'une feuille de calcul Excel ou d'un fichier CSV, mais les donn√©es peuvent √©galement √™tre enregistr√©es dans d'autres formats, comme un fichier JSON.

-vertical-

### Diff√©rence scraper-crawler

Les web scrapers peuvent se concentrer sur des pages ou sites web sp√©cifiques uniquement, tandis que les robots d'indexation suivront les liens et les pages d'indexation en continu.

-vertical-

### Web scraping en python

<p class="r-fit-text">
C'est le langage le plus populaire pour le web scraping, car il g√®re facilement la plupart des processus. Il propose √©galement diverses biblioth√®ques sp√©cialement con√ßues pour le web scraping. Scrapy est un framework d'exploration web open source tr√®s populaire, √©crit en Python. Il est id√©al pour le web scraping ainsi que pour l'extraction de donn√©es via des API. Beautiful soup est une autre biblioth√®que Python particuli√®rement adapt√©e au web scraping. Elle cr√©e un arbre d'analyse permettant d'extraire des donn√©es du code HTML d'un site web. Beautiful soup offre √©galement de nombreuses fonctionnalit√©s pour la navigation, la recherche et la modification de ces arbres d'analyse.
</p>

-vertical-

### Attention √† respecter le web!

Les sites donnent des informations sur la r√©cup√©ration de donn√©es qu'ils acceptent dans leurs `robots.txt`

on y retrouve :
- les agents qui sont autoriser √† Scrapper
- la limite de d√©bit
- ...


-vertical-

## üïØÔ∏è*Crawler* le webüïØÔ∏è

<aside class="notes">
    Soit on vous donne des donn√©es d√©j√† toutes pr√™tes:
    des donn√©es clients -> il faut faire des traitements Pour
    - anonymiser
    - nettoyer
    - : rendre exploitable
    Soit on vous dit juste ce dont vous avez besoin et il faut aller chercher les infos sur le net
</aside>

**Aller r√©cup√©rer le contenu des sites avec un crawler**

- `Selenium`
<pre><code>> from selenium import webdriver</code></pre>
‚û°Ô∏è Une bilioth√®que pour automatiser les int√©ractions entre python et le navigateur
- `Requests`
<pre><code>> import requests</code></pre>
‚û°Ô∏è La biblioth√®que de base pour requ√™ter le web depuis Python

-vertical-

## üïØÔ∏è*Scrapper* le webüïØÔ∏è

**R√©cup√©rer le contenu textuel** avec un scrapper

- `lxml`
<pre><code> from lxml import etree</code></pre>

<p class="r-fit-text">
‚û°Ô∏è La biblioth√®que de base pour traiter du xml/html
</p>

- `Beautiful Soup`
<pre><code>
from bs4 import BeautifulSoup
</code></pre>
<p class="r-fit-text">
‚û°Ô∏è Une biblioth√®que tr√®s r√©pendue pour faire √† peu pr√®s pareil que lxml
</p>
- scrapy
<pre><code>
    import scrapy
</code></pre>

-vertical-

## Documents Semi-Structur√©s

Pour naviguer dans le contenu html, on utilise les concepts √©tudi√©s en cours de documents structur√©s et notamment
**XPATH**

&rarr; [cheatsheet XPATH](https://devhints.io/xpath)

-vertical-

## Comment on fait ?

&rarr; Un [exemple](https://en.wikipedia.org/wiki/Entropy_(information_theory))

üí°`f12` pour ouvrir l'inspecteur dynamique

üí°`ctrl+U` pour ouvrir le code source de la page

<aside class="notes">
    dans un script
    on veut ouvrir la page avec requests
    copy xpath
</aside>

-vertical-

### √âviter le blocage IP¬†: proxys et rotation des agents utilisateurs

<p class="r-fit-text">
Certains sites ne permettent pas de r√©cup√©rer les informations contenue en leur sein.
</p>
<p class="r-fit-text">
Pourtant, en temps d'utilisateur, vous √™tes autoris√©s √† les consulter.
</p>
<p class="r-fit-text">
Comment est ce que les syst√®mes arrivent √† d√©celer qui demande l'information ?
&rarr; via l'adresse IP de l'utilisateur
</p>

<p class="r-fit-text">
Lorsqu'un utilisateur robot fait de nombreuses requ√™tes successive √† un serveur, le serveur bloque cette adresse IP.
</p>
<p class="r-fit-text">
Evitez de faire des requ√™tes rapides √† un serveur car vous serez vite bloqu√©s.
</p>

-vertical-

<h2 class="r-fit-text">üî≠Qu'est ce qu'on r√©cup√®re ?üî≠</h2>

<aside class="notes">
    On a vu la derni√®re fois qu'on pouvait avoir √† peu pr√®s n'importe quoi comme nature de donn√©es de nos corpus
    Est ce que vous avez des id√©es de ce qui peut nous int√©resser comme nature de donn√©es en NLP ?
</aside>

<ul>
    <li class="fragment">Des images <img
            src="https://upload.wikimedia.org/wikipedia/commons/b/b7/Manuscript_text_on_properties_of_the_mandrake_plant_Wellcome_L0037351.jpg"
            width="450" height="300"></li>
    <li class="fragment">Des sons üîä</li>
    <li class="fragment">Des textes üî°</li>
</ul>

-vertical-

<aside class="notes">
    Comment exploiter ces donn√©es ?
    - Souvent pour faire de l'analyse s√©mantique, on passe par une repr√©sentation textuelle
    -> transformer l'oral en texte avec Whisper
    -> transformer les images en textes avec OCR
</aside>

## Stocker les donn√©es pour le traitement

On veut stocker des donn√©es propres et facilement accessibles pour un traitement de machine learning.

La biblioth√®que reine du traitement des donn√©es en python : `pandas`

-vertical-

### Pandas

Pandas est compatible avec de nombreux format de donn√©es:
- xml
- json
- parquet
- csv
- ...

-vertical-

### huggingface Datasets

<p class="r-fit-text">
huggingface propose aussi sa propre biblioth√®que de traitement de donn√©es : `datasets`
</p>
<p class="r-fit-text">
Elle est particuli√®rement utile pour r√©cup√©rer des corpus pr√©-existant.
</p>
<p class="r-fit-text">
Dans ce cas, il n'est pas n√©cessaire de passer par les √©tapes vues pr√©cedemment car la libairie s'occupe d'elle m√™me de
pr√©parer les donn√©es pour python
</p>
<p class="r-fit-text">
En revanche, il est important de comprendre commment la biblioth√®que fonctionne pour cr√©er votre propre corpus et le
publier sur la plateforme.
</p>
<p class="r-fit-text">
Les donn√©es y sont souvent stock√©es en parquet
</p>

-vertical-

### üñºÔ∏èConvertir des images en texteüñºÔ∏è

<div class="r-stack">
    <div>
        <p>Les OCR</p>
        <ul>
            <li>Avec Python :</li>
            <ul>
                <li>py-tesseract</li>
                <li>doctr</li>
            </ul>
            <li>Avec les mod√®les multimodaux ? :</li>
            <ul>
                <li>GPT-4</li>
                <li>Gemini</li>
            </ul>
        </ul>
    </div>

    <img class="fragment"
        src="https://raw.githubusercontent.com/Yuliang-Liu/MultimodalOCR/main/images/GPT4V_Gemini.png"/>
</div>

-vertical-

### üñºÔ∏èConvertir des images en texteüñºÔ∏è
#### Comment √ßa marche ‚ùì

<img src="https://upload.wikimedia.org/wikipedia/commons/f/f7/MnistExamplesModified.png"/>

-vertical-

### üîäConvertir les audio en texteüîä

Les mod√®les de speech-to-text
- Whisper
- Canary

-vertical-

### üßºConvertir du texte en texte (propre)üßº
#### (Denoising Data)

- Comparer √† un vocabulaire existant
- (distance d'√©dition : Levenshtein)
- Utiliser des mod√®les (avec les mask token pred.)
- Utiliser des LLM

-horizontal-

## Le point *bonne pratique*

Suivre les [conseils du MIT](https://mitcommlab.mit.edu/broad/commkit/file-structure/#BestPracticesFileStructures)

### L'importance de l'organisation des fichiers

<p class="r-fit-text">
La coh√©rence est essentielle. Comme pour se d√©placer dans la maison, il est utile de savoir o√π se trouve chaque √©l√©ment et de s'assurer qu'il est rang√© dans un ordre logique (esp√©rons que vos ustensiles de cuisine ne se trouvent pas dans votre salle de bain). Il en va de m√™me pour le codage. Savoir o√π se trouvent les fichiers, quand utiliser tel code pour telle op√©ration et comment trouver les r√©sultats, donn√©es et chiffres associ√©s peut non seulement optimiser la productivit√©, mais aussi favoriser la coh√©rence (m√™me entre plusieurs projets) et le partage.
</p>

-vertical-

### L'importance de l'organisation des fichiers

L'emplacement et l'organisation de vos fichiers peuvent √™tre consid√©r√©s comme une carte globale de vos projets de codage. Comme pour une l√©gende de carte, vous devez d√©finir un ensemble d'attentes concernant l'emplacement des diff√©rentes parties du projet et leur ordre d'assemblage.

-vertical-

### Pourquoi le faire¬†: pour les autres

<p class="r-fit-text">
M√™me si vous travaillez sur un devoir, il est pr√©f√©rable de garder √† l'esprit que votre travail sera partag√© et reproduit par d'autres. Pour cela, vous devez organiser votre code de mani√®re √† ce que les nouveaux arrivants puissent acc√©der rapidement aux √©l√©ments cl√©s de votre projet sans consulter la documentation ni cliquer sans but dans les fichiers. D'une certaine mani√®re, vous souhaitez que les autres vous remercient. Ils vous remercieront, esp√©rons-le, pour¬†:
</p>

- le temps gagn√© √† apprendre la structure de votre projet¬†;
- la possibilit√© de collaborer plus facilement avec vous¬†;
- la compr√©hension rapide de la mani√®re dont votre analyse a √©t√© r√©alis√©e¬†;
- la possibilit√© de reproduire rapidement votre code, ce qui renforce la confiance du collaborateur et la v√¥tre.

-vertical-

### Pourquoi le faire¬†: pour vous

<p class="r-fit-text">
Si vous avez d√©j√† organis√© votre bureau pour lib√©rer de l'espace, tant physique que mental, vos projets de code m√©ritent la m√™me attention. Le temps investi pour apprendre √† organiser votre code d√®s maintenant vous aidera √† rationaliser vos projets futurs et √† gagner en coh√©rence entre eux. M√™me si vous travaillez sur un devoir rapide, pensez aux centaines de devoirs similaires pour lesquels vous devez cr√©er un dossier, puis bricoler quelques fichiers (nous vous d√©conseillons de tout mettre sur votre bureau). Ainsi, que vous travailliez sur des projets de petite ou de grande envergure, √©tablir une structure standard renforcera la coh√©rence de votre travail et r√©duira le temps n√©cessaire √† la r√©daction de votre code standard.
</p>

-vertical-

### Pourquoi le faire : pour le vous futur

<img src="https://mitcommlab.mit.edu/broad/wp-content/uploads/sites/5/2019/11/file-structure-confusion-700x494.png" height=400 />

-vertical-

### Pourquoi le faire : pour le vous futur

<p class="r-fit-text">
√ätre confus n'est jamais agr√©able, surtout si vous en √™tes la cause. Revenir au code et oublier o√π sont plac√©s vos fichiers, ou pire, lesquels utiliser (la m√©thode t√¢tonnement fatale consistant √† utiliser les suffixes fichier1.py, fichier-v1.py, fichier-mod1.py ou fichier-essayez-celui-ci-v1.py) est une exp√©rience p√©nible. Pire encore, cela limite la capacit√© √† reproduire votre code.
</p>
<p class="r-fit-text">
Par cons√©quent, √©tablir une coh√©rence d√®s le d√©part ‚Äì en commen√ßant par une structure de fichiers et une convention de nommage standardis√©es ‚Äì sera b√©n√©fique pour votre futur. L'objectif est de remercier votre pass√©.
</p>

-vertical-

### Exemple √† suivre

```
PROJECT/
‚îú‚îÄ‚îÄ bin/ <- compiled binaries. 
‚îú‚îÄ‚îÄ data/ 
‚îÇ ‚îú‚îÄ‚îÄ raw/ 
‚îÇ ‚îî‚îÄ‚îÄ clean/ 
‚îÇ 
‚îú‚îÄ‚îÄ figures/ <- figures used in place of a "results"folder. 
‚îú‚îÄ‚îÄ scripts/ 
‚îÇ ‚îú‚îÄ‚îÄ process/ <- scripts to maniuplate data between raw, cleaned final stages. 
‚îÇ ‚îî‚îÄ‚îÄ plot/ <- intermediate plotting. 
‚îÇ 
‚îú‚îÄ‚îÄ src 
‚îÇ ‚îú‚îÄ‚îÄ model1/ <- various experimental models. 
‚îÇ ‚îú‚îÄ‚îÄ model2/ 
‚îÇ ‚îî‚îÄ‚îÄ model3/
‚îÇ 
‚îú‚îÄ‚îÄ LICENSE 
‚îú‚îÄ‚îÄ Makefile 
‚îî‚îÄ‚îÄ readme.md
``` 
-vertical-

### Exemple pour un projet python

```
PROJECT/
‚îú‚îÄ‚îÄ data/ 
‚îÇ ‚îú‚îÄ‚îÄ raw/ 
‚îÇ ‚îî‚îÄ‚îÄ clean/ 
‚îÇ 
‚îú‚îÄ‚îÄ figures/ <- figures used in place of a "results"folder. 
‚îú‚îÄ‚îÄ src/ 
‚îÇ ‚îú‚îÄ‚îÄ process/ <- scripts to maniuplate data between raw, cleaned final stages. 
‚îÇ ‚îî‚îÄ‚îÄ plot/ <- intermediate plotting. 
‚îÇ 
‚îú‚îÄ‚îÄ bin 
‚îÇ ‚îú‚îÄ‚îÄ model1/ <- various experimental models. 
‚îÇ ‚îú‚îÄ‚îÄ model2/ 
‚îÇ ‚îî‚îÄ‚îÄ model3/
‚îÇ 
‚îú‚îÄ‚îÄ LICENSE 
‚îú‚îÄ‚îÄ Makefile 
‚îî‚îÄ‚îÄ readme.md
``` 


-vertical- 

## Quiz 2

3. Dans un projet python, quel est le nom usuel du dossier dans lequel on mets les fichiers de scripts ?

4. A quoi doit-on faire attention pour ne pas outrepasser la limite de d√©bit lorsque l'on scrappe un site web ?


-horizontal-


# TP : R√©cuperer votre corpus de travail √† partir d'une resource web

mettez votre script de crawling et de scraping sur votre github en respectant l'arborescence de dossiers pr√©sent√© aujourd'hui.

<ul>
    <li>‚ö†Ô∏èNe r√©cup√©rez que des donn√©es qu'il est l√©gal de r√©cup√©rer</li>
    <li>‚ö†Ô∏èVous n'avez pas √† commit les fichiers r√©cup√©r√©s dans votre repo &rarr; *push* des gros fichiers peut faire
        exploser votre git</li>
    <li>Votre code suffira pour l'√©valuation</li>
</ul>

-vertical-

## Quelques pr√©cisions sur l'√©valuation

Le projet √† rendre comprend:

- l'analyse d'un corpus pr√©-existant
- la constitution d'un corpus similaire √† partir de donn√©es ouverte
- l'applications de visualisation sur ces donn√©es
- l'√©valuation du corpus constitu√©
