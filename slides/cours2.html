---
layout: presentation
title: Cours2
---
# Outils de Traitement de Corpus
cours 2
-vertical-
# Rappel du cours prÃ©cÃ©dent

<h2 class="r-fit-text">ğŸ“šğŸ“„Rappels sur les corpusğŸ“šğŸ“„</h2>
<h2 class="r-fit-text">ğŸ› ï¸Focus sur les tÃ¢chesğŸ› ï¸</h2>
<h2 class="r-fit-text">ğŸ”OÃ¹ trouver des corpusğŸ”</h2>

-vertical-
# Cours 2

<h2 class="r-fit-text">ğŸ›ï¸RÃ©cupÃ©rer de nouvelles donnÃ©esğŸ›ï¸</h2>
<h2 class="r-fit-text">â›½Rendre les donnÃ©es exploitableâ›½</h2>
<h2 class="r-fit-text">ğŸ”§Les Outils pour explorer les donnÃ©esğŸ”§</h2>

-horizontal-

## ğŸ›ï¸RÃ©cupÃ©rer de nouvelles donnÃ©esğŸ›ï¸

-vertical-

## Pourquoi ?

On parlait des RGPD : dans un cadre professionnel, on peut Ãªtre ammenÃ© Ã  avoir des donnÃ©es qu'il n'y a pas sur le web

Parfois les datasets pour certaines langues/tÃ¢ches ne sont pas disponibles &rarr; il faut pourvoir se dÃ©brouiller

-vertical-

## ğŸ•¯ï¸*Scrapper* le webğŸ•¯ï¸

<aside class="notes">
    Soit on vous donne des donnÃ©es dÃ©jÃ  toutes prÃªtes:
    des donnÃ©es clients -> il faut faire des traitements Pour
        - anonymiser
        - nettoyer
        - : rendre exploitable
    Soit on vous dit juste ce dont vous avez besoin et il faut aller chercher les infos sur le net
</aside>

- `Selenium`
`> from selenium import webdriver`
â¡ï¸ Une biliothÃ¨que pour automatiser les intÃ©ractions entre python et le navigateur
- `Requests` 
`> import requests`
â¡ï¸ La bibliothÃ¨que de base pour requÃªter le web depuis Python
- `lxml`
`> from lxml import etree`
â¡ï¸ La bibliothÃ¨que de base pour traiter du xml/html
- `Beautiful Soup`
`> from bs4 import BeautifulSoup`
â¡ï¸ Une bibliothÃ¨que trÃ¨s rÃ©pendue pour faire Ã  peu prÃ¨s pareil que lxml
    
-vertical-

## Documents StructurÃ©s

Pour naviguer dans le contenu html, on utilise les concepts Ã©tudiÃ©s en cours de documents structurÃ©s et notamment **XPATH**

-vertical-

## ğŸ”­Qu'est ce qu'on rÃ©cupÃ¨re ?ğŸ”­

<aside class="notes">
    On a vu la derniÃ¨re fois qu'on pouvait avoir Ã  peu prÃ¨s n'importe quoi comme nature de donnÃ©es de nos corpus
    Est ce que vous avez des idÃ©es de ce qui peut nous intÃ©resser comme nature de donnÃ©es en NLP ?
</aside>

<ul>
    <li class="fragment">Des images ğŸ–¼<img class="fragment fade-in-then-out" src="https://upload.wikimedia.org/wikipedia/commons/b/b7/Manuscript_text_on_properties_of_the_mandrake_plant_Wellcome_L0037351.jpg" width="450" height="300"></li>
    <li class="fragment">Des sons ğŸ”Š</li>
    <li class="fragment">Des textes ğŸ”¡</li>
</ul>

-horizontal-

<aside class="notes">
    Comment exploiter ces donnÃ©es ?
    - Souvent pour faire de l'analyse sÃ©mantique, on passe par une reprÃ©sentation textuelle
    -> transformer l'oral en texte avec Whisper
    -> transformer les images en textes avec OCR
</aside>

## â›½Rendre les donnÃ©es exploitableâ›½

-vertical-

### ğŸ–¼Convertir des images en texteğŸ–¼

<div class="r-stack">
<p>
Les OCR
<ul>
    <li>Avec Python :</li>
        <ul>
            <li>py-tesseract</li>
            <li>doctr</li>
        </ul>
    <li>Avec les modÃ¨les multimodaux ? :</li>
        <ul>
            <li>GPT-4</li>
            <li>Gemini</li>
        </ul>
</ul>
</p>

<img class="fragment" src="https://github.com/Yuliang-Liu/MultimodalOCR/blob/main/images/GPT4V_Gemini.png">
</div>

-vertical-

### ğŸ–¼Convertir des images en texteğŸ–¼
#### Comment Ã§a marche â“

<img src="https://www.google.com/url?sa=i&url=https%3A%2F%2Fpaperswithcode.com%2Fdataset%2Fmnist&psig=AOvVaw0P2EZQuMkeKwZC3oqNspIg&ust=1710155544961000&source=images&cd=vfe&opi=89978449&ved=0CBMQjRxqFwoTCMDk-f_H6YQDFQAAAAAdAAAAABAE">

-vertical-

### ğŸ”ŠConvertir les audio en texteğŸ”Š

Les modÃ¨les de speech-to-text
- Whisper

-vertical-

### ğŸ§¼Convertir du texte en texte (propre)ğŸ§¼
### (Denoising Data)

- Comparer Ã  un vocabulaire existant
    - (distance d'Ã©dition : Levenshtein)
- Utiliser des modÃ¨les
- Utiliser des LLM

<aside class="notes">ProblÃ¨mes des OOV : Out of Vocabulary</aside>

-vertical-

### ğŸ·ï¸Annoter ses donnÃ©esğŸ·ï¸

<aside class="notes">
    Si on cherche Ã  faire de la classification, on va peut Ãªtre devoir annoter ses donnÃ©es
    Soit on c'est de la classification de documents et on peut peut-Ãªtre rÃ©cupÃ©rer les info 
    au moment de la rÃ©cupÃ©ration
</aside>
**Au niveau des "mots"**

- Etiquetage Morphosyntaxique
- EntitÃ© NommÃ©e

**Au niveau des documents**

- genre

-vertical-

### âš–ï¸Le balancement des classesâš–ï¸

- scikit Learn
- Dataset Class

-horizontal-

â“ Des questions â“

ğŸ’¡ Des idÃ©es ğŸ’¡

-vertical-

## Le point bonne pratique

Suivre les [conseils du MIT](https://mitcommlab.mit.edu/broad/commkit/file-structure/#BestPracticesFileStructures)

```
PROJECT/
â”œâ”€â”€ bin/            <- compiled binaries. 
â”œâ”€â”€ data/ 
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ clean/
â”‚
â”œâ”€â”€ figures/        <- figures used in place of a "results" folder. 
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ process/    <- scripts to maniuplate data between raw, cleaned, final stages.
â”‚   â””â”€â”€ plot/	      <- intermediate plotting.
â”‚
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ model1/     <- various experimental models.
â”‚   â”œâ”€â”€ model2/
â”‚   â””â”€â”€ model3/
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â””â”€â”€ readme.md
```

-vertical-

<ol>
<li>Initialiser les dossiers de votre repo</li>
<ul>
    <li>rÃ©flÃ©chissez aux traitements que l'on va effectuer pendant le cours : de quels dossiers vous allez avoir besoin</li>
</ul>
<li>Mettez en place un script python pour rÃ©cupÃ©rer automatiquement des donnÃ©es depuis le web (quelques Ã©lÃ©ments suffiront)</li>
<ul>
    <li>âš Ne rÃ©cupÃ©rez que des donnÃ©es qu'il est lÃ©gal de rÃ©cupÃ©rer :</li>
    <li> pas de donnÃ©es contenant des informations identifiantes (pseudo, dates de publiction, ...)</li>
    <li> n'importe quoi qui concerne des individus</li>
</ul>
<li>Nettoyez ces donnÃ©es pour les prÃ©senter sous forme de texte</li>
<p>âš Vous n'avez pas Ã  commit les fichiers rÃ©cupÃ©rÃ©s dans votre repo &rarr; *push* des gros fichiers peut faire exploser votre git</p>
<p>Votre code suffira pour l'Ã©valuation</p>
</ol>
