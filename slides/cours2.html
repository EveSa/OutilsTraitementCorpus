---
layout: presentation
title: Cours2
---
# Outils de Traitement de Corpus
cours 2
-vertical-
# Rappel du cours précédent

<h2 class="r-fit-text">📚📄Rappels sur les corpus📚📄</h2>
<h2 class="r-fit-text">🛠️Focus sur les tâches🛠️</h2>
<h2 class="r-fit-text">🔎Où trouver des corpus🔍</h2>

-vertical-
# Cours 2

<h2 class="r-fit-text">🛍️Récupérer de nouvelles données🛍️</h2>
<h2 class="r-fit-text">⛽Rendre les données exploitable⛽</h2>
<h2 class="r-fit-text">🔧Les Outils pour explorer les données🔧</h2>

-horizontal-

## 🛍️Récupérer de nouvelles données🛍️

-vertical-

## Pourquoi ?

On parlait des RGPD : dans un cadre professionnel, on peut être ammené à avoir des données qu'il n'y a pas sur le web

Parfois les datasets pour certaines langues/tâches ne sont pas disponibles &rarr; il faut pourvoir se débrouiller

-vertical-

## 🕯️*Scrapper* le web🕯️

<aside class="notes">
    Soit on vous donne des données déjà toutes prêtes:
    des données clients -> il faut faire des traitements Pour
        - anonymiser
        - nettoyer
        - : rendre exploitable
    Soit on vous dit juste ce dont vous avez besoin et il faut aller chercher les infos sur le net
</aside>

**Aller récupérer le contenu des sites**

- `Selenium`
<pre><code>> from selenium import webdriver</code></pre>
➡️ Une biliothèque pour automatiser les intéractions entre python et le navigateur
- `Requests` 
<pre><code>> import requests</code></pre>
➡️ La bibliothèque de base pour requêter le web depuis Python

-vertical-

## 🕯️*Scrapper* le web🕯️

**Récupérer le contenu textuel**

- `lxml`
<pre><code> from lxml import etree</code></pre>
➡️ La bibliothèque de base pour traiter du xml/html
- `Beautiful Soup`
<pre><code>
from bs4 import BeautifulSoup
</code></pre>
➡️ Une bibliothèque très répendue pour faire à peu près pareil que lxml
    
-vertical-

## Documents Structurés

Pour naviguer dans le contenu html, on utilise les concepts étudiés en cours de documents structurés et notamment **XPATH**

-vertical-

<h2 class="r-fit-text">🔭Qu'est ce qu'on récupère ?🔭</h2>

<aside class="notes">
    On a vu la dernière fois qu'on pouvait avoir à peu près n'importe quoi comme nature de données de nos corpus
    Est ce que vous avez des idées de ce qui peut nous intéresser comme nature de données en NLP ?
</aside>

<ul>
    <li class="fragment">Des images <img src="https://upload.wikimedia.org/wikipedia/commons/b/b7/Manuscript_text_on_properties_of_the_mandrake_plant_Wellcome_L0037351.jpg" width="450" height="300"></li>
    <li class="fragment">Des sons 🔊</li>
    <li class="fragment">Des textes 🔡</li>
</ul>

-horizontal-

<aside class="notes">
    Comment exploiter ces données ?
    - Souvent pour faire de l'analyse sémantique, on passe par une représentation textuelle
    -> transformer l'oral en texte avec Whisper
    -> transformer les images en textes avec OCR
</aside>

## ⛽Rendre les données exploitable⛽

-vertical-

### 🖼️Convertir des images en texte🖼️

<div class="r-stack">
<p>Les OCR</p>
<ul>
    <li>Avec Python :</li>
        <ul>
            <li>py-tesseract</li>
            <li>doctr</li>
        </ul>
    <li>Avec les modèles multimodaux ? :</li>
        <ul>
            <li>GPT-4</li>
            <li>Gemini</li>
        </ul>
</ul>

<img class="fragment" src="https://raw.githubusercontent.com/Yuliang-Liu/MultimodalOCR/main/images/GPT4V_Gemini.png">
</div>

-vertical-

### 🖼️Convertir des images en texte🖼️
#### Comment ça marche ❓

<img src="https://upload.wikimedia.org/wikipedia/commons/f/f7/MnistExamplesModified.png">

-vertical-

### 🔊Convertir les audio en texte🔊

Les modèles de speech-to-text
- Whisper

-vertical-

### 🧼Convertir du texte en texte (propre)🧼
#### (Denoising Data)

- Comparer à un vocabulaire existant
    - (distance d'édition : Levenshtein)
- Utiliser des modèles
- Utiliser des LLM

<aside class="notes">Problèmes des OOV : Out of Vocabulary</aside>

-vertical-

### 🏷️Annoter ses données🏷️

<aside class="notes">
    Si on cherche à faire de la classification, on va peut être devoir annoter ses données
    Soit on c'est de la classification de documents et on peut peut-être récupérer les info 
    au moment de la récupération
</aside>

**Au niveau des "mots"**

- Etiquetage Morphosyntaxique
- Entité Nommée

**Au niveau des documents**

- genre

-vertical-

### Les outils d'annotation

**Pour le POS Tagging**

Pour annoter à la main :
- CoNLL-U : un format

Pour annoter automatiquement :
- SpaCy : un outil automatique performant
- Stanza : l'outil de POS Tagging de Standford

<pre><code>
import stanza
import spacy_stanza
</code></pre>

-vertical-

### Les outils d'annotation

**Pour la reconnaissance d'entités nommées**

Pour annoter à la main :
- Glozz

Pour annoter avec des règles d'annotation :
- Unitex
- GATE
- SpaCy Matcher

Pour annoter automatiquement :
- SpaCy (again)

-vertical-

Le problème, c'est que pour annoter automatiquement, on a besoin de modèle.

Et pour avoir des modèles, on a besoin de données annotées...

Parfois la phase d'annotation manuelle ne peut pas être omise

-vertical-

### ⚖️Le balancement des classes⚖️

- scikit Learn
- Dataset Class

-horizontal-

❓ Des questions ❓

💡 Des idées 💡

-vertical-

## Le point bonne pratique

Suivre les [conseils du MIT](https://mitcommlab.mit.edu/broad/commkit/file-structure/#BestPracticesFileStructures)

```
PROJECT/
├── bin/            <- compiled binaries. 
├── data/ 
│   ├── raw/
│   └── clean/
│
├── figures/        <- figures used in place of a "results" folder. 
├── scripts/
│   ├── process/    <- scripts to maniuplate data between raw, cleaned, final stages.
│   └── plot/	      <- intermediate plotting.
│
├── src
│   ├── model1/     <- various experimental models.
│   ├── model2/
│   └── model3/
│
├── LICENSE
├── Makefile
└── readme.md
```

-vertical-

<div class="r-stack">
<ol class="fade-out">
<li>Initialiser les dossiers de votre repo</li>
<ul>
    <li>réfléchissez aux traitements que l'on va effectuer pendant le cours : de quels dossiers vous allez avoir besoin</li>
</ul>
<li>Mettez en place un script python pour récupérer automatiquement des données depuis le web (quelques éléments suffiront)</li>
<li>Nettoyez ces données pour les présenter sous forme de texte</li>
</ol>
<ul class="fragment">
    <li>⚠️Ne récupérez que des données qu'il est légal de récupérer</li>
    <li>⚠️Vous n'avez pas à commit les fichiers récupérés dans votre repo &rarr; *push* des gros fichiers peut faire exploser votre git (cf. Le point bonne pratique de la semaine dernière)</li>
    <li>Votre code suffira pour l'évaluation</li>
</ul>
</div>