---
layout: presentation
title: Cours2
---
# Outils de Traitement de Corpus
cours 2
-vertical-
# Rappel du cours précédent

<h2 class="r-fit-text">📚📄Rappels sur les corpus📚📄</h2>
<h2 class="r-fit-text">🛠️Focus sur les tâches🛠️</h2>
<h2 class="r-fit-text">🔎Où trouver des corpus🔍</h2>

-vertical-
# Cours 2

<h2 class="r-fit-text">🛍️Récupérer de nouvelles données🛍️</h2>
<h2 class="r-fit-text">⛽Rendre les données exploitable⛽</h2>
<h2 class="r-fit-text">🔧Les Outils pour explorer les données🔧</h2>

-horizontal-

## 🛍️Récupérer de nouvelles données🛍️

-vertical-

## Pourquoi ?

On parlait des RGPD : dans un cadre professionnel, on peut être ammené à avoir des données qu'il n'y a pas sur le web

Parfois les datasets pour certaines langues/tâches ne sont pas disponibles &rarr; il faut pourvoir se débrouiller

-vertical-

## 🕯️*Scrapper* le web🕯️

<aside class="notes">
    Soit on vous donne des données déjà toutes prêtes:
    des données clients -> il faut faire des traitements Pour
        - anonymiser
        - nettoyer
        - : rendre exploitable
    Soit on vous dit juste ce dont vous avez besoin et il faut aller chercher les infos sur le net
</aside>

- `Selenium`
`> from selenium import webdriver`
➡️ Une biliothèque pour automatiser les intéractions entre python et le navigateur
- `Requests` 
`> import requests`
➡️ La bibliothèque de base pour requêter le web depuis Python
- `lxml`
`> from lxml import etree`
➡️ La bibliothèque de base pour traiter du xml/html
- `Beautiful Soup`
`> from bs4 import BeautifulSoup`
➡️ Une bibliothèque très répendue pour faire à peu près pareil que lxml
    
-vertical-

## Documents Structurés

Pour naviguer dans le contenu html, on utilise les concepts étudiés en cours de documents structurés et notamment **XPATH**

-vertical-

## 🔭Qu'est ce qu'on récupère ?🔭

<aside class="notes">
    On a vu la dernière fois qu'on pouvait avoir à peu près n'importe quoi comme nature de données de nos corpus
    Est ce que vous avez des idées de ce qui peut nous intéresser comme nature de données en NLP ?
</aside>

<ul>
    <li class="fragment">Des images 🖼<img class="fragment fade-in-then-out" src="https://upload.wikimedia.org/wikipedia/commons/b/b7/Manuscript_text_on_properties_of_the_mandrake_plant_Wellcome_L0037351.jpg" width="450" height="300"></li>
    <li class="fragment">Des sons 🔊</li>
    <li class="fragment">Des textes 🔡</li>
</ul>

-horizontal-

<aside class="notes">
    Comment exploiter ces données ?
    - Souvent pour faire de l'analyse sémantique, on passe par une représentation textuelle
    -> transformer l'oral en texte avec Whisper
    -> transformer les images en textes avec OCR
</aside>

## ⛽Rendre les données exploitable⛽

-vertical-

### 🖼Convertir des images en texte🖼

<div class="r-stack">
<p>
Les OCR
<ul>
    <li>Avec Python :</li>
        <ul>
            <li>py-tesseract</li>
            <li>doctr</li>
        </ul>
    <li>Avec les modèles multimodaux ? :</li>
        <ul>
            <li>GPT-4</li>
            <li>Gemini</li>
        </ul>
</ul>
</p>

<img class="fragment" src="https://github.com/Yuliang-Liu/MultimodalOCR/blob/main/images/GPT4V_Gemini.png">
</div>

-vertical-

### 🖼Convertir des images en texte🖼
#### Comment ça marche ❓

<img src="https://www.google.com/url?sa=i&url=https%3A%2F%2Fpaperswithcode.com%2Fdataset%2Fmnist&psig=AOvVaw0P2EZQuMkeKwZC3oqNspIg&ust=1710155544961000&source=images&cd=vfe&opi=89978449&ved=0CBMQjRxqFwoTCMDk-f_H6YQDFQAAAAAdAAAAABAE">

-vertical-

### 🔊Convertir les audio en texte🔊

Les modèles de speech-to-text
- Whisper

-vertical-

### 🧼Convertir du texte en texte (propre)🧼
### (Denoising Data)

- Comparer à un vocabulaire existant
    - (distance d'édition : Levenshtein)
- Utiliser des modèles
- Utiliser des LLM

<aside class="notes">Problèmes des OOV : Out of Vocabulary</aside>

-vertical-

### 🏷️Annoter ses données🏷️

<aside class="notes">
    Si on cherche à faire de la classification, on va peut être devoir annoter ses données
    Soit on c'est de la classification de documents et on peut peut-être récupérer les info 
    au moment de la récupération
</aside>
**Au niveau des "mots"**

- Etiquetage Morphosyntaxique
- Entité Nommée

**Au niveau des documents**

- genre

-vertical-

### ⚖️Le balancement des classes⚖️

- scikit Learn
- Dataset Class

-horizontal-

❓ Des questions ❓

💡 Des idées 💡

-vertical-

## Le point bonne pratique

Suivre les [conseils du MIT](https://mitcommlab.mit.edu/broad/commkit/file-structure/#BestPracticesFileStructures)

```
PROJECT/
├── bin/            <- compiled binaries. 
├── data/ 
│   ├── raw/
│   └── clean/
│
├── figures/        <- figures used in place of a "results" folder. 
├── scripts/
│   ├── process/    <- scripts to maniuplate data between raw, cleaned, final stages.
│   └── plot/	      <- intermediate plotting.
│
├── src
│   ├── model1/     <- various experimental models.
│   ├── model2/
│   └── model3/
│
├── LICENSE
├── Makefile
└── readme.md
```

-vertical-

<ol>
<li>Initialiser les dossiers de votre repo</li>
<ul>
    <li>réfléchissez aux traitements que l'on va effectuer pendant le cours : de quels dossiers vous allez avoir besoin</li>
</ul>
<li>Mettez en place un script python pour récupérer automatiquement des données depuis le web (quelques éléments suffiront)</li>
<ul>
    <li>⚠Ne récupérez que des données qu'il est légal de récupérer :</li>
    <li> pas de données contenant des informations identifiantes (pseudo, dates de publiction, ...)</li>
    <li> n'importe quoi qui concerne des individus</li>
</ul>
<li>Nettoyez ces données pour les présenter sous forme de texte</li>
<p>⚠Vous n'avez pas à commit les fichiers récupérés dans votre repo &rarr; *push* des gros fichiers peut faire exploser votre git</p>
<p>Votre code suffira pour l'évaluation</p>
</ol>
